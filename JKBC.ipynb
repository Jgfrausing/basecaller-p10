{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Databunch for Basecalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import jkbc.utils.postprocessing as pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK_ID = 4\n",
    "C = 5\n",
    "D_in = 300\n",
    "D_h = 200\n",
    "D_out_max = 50\n",
    "BS = 64 # batch size\n",
    "LR = 0.05\n",
    "\n",
    "#DEVICE = torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/notebooks/storage/bc_data/test_dataset.hdf5'),\n",
       " PosixPath('/notebooks/storage/bc_data/small_umi16to9.hdf5')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = \"/notebooks/storage/\" # Change this line if the data is located elsewhere\n",
    "path_data = Path(base_dir +\"/bc_data\")\n",
    "path_data.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_set_name = 'test_dataset.hdf5'\n",
    "data_set_name = 'small_umi16to9.hdf5'\n",
    "dc_test = prep.SignalCollection(path_data/data_set_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0000b441-4cc6-42a7-bdfe-310f9e560e57 (0)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "ref_to_signal and reference has different lengths",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-337-1be4d71f5f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# There is just a single piece of data in dc_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdc_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/course-v3/kasper/basecaller-p10/jkbc/jkbc/utils/preprocessing.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing {self.read_idx[pos]} ({pos})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mx_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/course-v3/kasper/basecaller-p10/jkbc/jkbc/utils/preprocessing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, read_id_index)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mread_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread_id_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_to_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbc_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_info_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mnum_of_bases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/course-v3/kasper/basecaller-p10/jkbc/jkbc/utils/files.py\u001b[0m in \u001b[0;36mget_read_info_from_file\u001b[0;34m(file_path, read_id)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;34m\"\"\"Get signal, ref_to_signal, and reference for a given read_id from a hdf5 file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhdf5_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_read_info_from_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/course-v3/kasper/basecaller-p10/jkbc/jkbc/utils/files.py\u001b[0m in \u001b[0;36mget_read_info_from_open_file\u001b[0;34m(hdf5_file, read_id)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mreference\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdf5_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reads'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_to_signal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ref_to_signal and reference has different lengths\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_to_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ref_to_signal and reference has different lengths"
     ]
    }
   ],
   "source": [
    "# There is just a single piece of data in dc_test\n",
    "for d in dc_test.generator():\n",
    "    data = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fields = np.array(data.x), np.array(data.y), data.x_lengths, data.y_lengths, data.reference\n",
    "x, y, x_lengths, y_lengths, reference = data_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (930, 300), x_lengths: (930, 1), y: (930, 6), y_lengths: (930, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'x: {x.shape}, x_lengths: {x_lengths.shape}, y: {y.shape}, y_lengths: {y_lengths.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('x: ', numpy.ndarray, (300, 930, 1), 'y: ', numpy.ndarray, (930, 50))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the x's to fit our model\n",
    "x_train = x.reshape((D_in, BS, 1))\n",
    "\n",
    "# The add_label_padding takes a nested list, so we use the data.y, should be changed\n",
    "y_train = prep.add_label_padding(labels = data.y, fixed_label_len = D_out_max, padding_id = BLANK_ID)\n",
    "\"x: \", type(x_train), x_train.shape, \"y: \", type(y_train), y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn everything into tensors\n",
    "mk_tensor_long = partial(torch.tensor, dtype = torch.long, device = DEVICE)\n",
    "mk_tensor_float = partial(torch.tensor, dtype = torch.float, device = DEVICE)\n",
    "x_train = mk_tensor_float(x_train)\n",
    "y_train, x_lengths, y_lengths = map(mk_tensor_long, (y_train, x_lengths, y_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(1, D_h)\n",
    "        self.lin2 = nn.Linear(D_h, C)\n",
    "    \n",
    "    #   forward(self, x: Tensor[D_in, BS, 1]) -> Tensor[D_in, BS, C]\n",
    "    def forward(self, xb):\n",
    "        xb_ = self.lin1(xb).clamp(min=0)\n",
    "        return self.lin2(xb_)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_loss = nn.CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n: int) -> None:\n",
    "    for t in range(n):\n",
    "        # forward pass\n",
    "        y_pred = model(x_train)\n",
    "        \n",
    "        loss = ctc_loss(y_pred, y_train, x_lengths, y_lengths)\n",
    "        \n",
    "        if t % 100 == 99:\n",
    "            print(t, loss.item())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 -13.010493278503418\n"
     ]
    }
   ],
   "source": [
    "#train(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_t, x_valid_t = x_train[:, :500].reshape((500, 300, 1)), x_train[:, 800:].reshape((130, 300, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_t, y_valid_t = y_train[:500], y_train[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 300, 1]),\n",
       " torch.Size([500, 50]),\n",
       " torch.Size([130, 300, 1]),\n",
       " torch.Size([130, 50]))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_t.shape, y_train_t.shape, x_valid_t.shape, y_valid_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = TensorDataset(x_train_t, y_train_t)\n",
    "ds_valid = TensorDataset(x_valid_t, y_valid_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(ds_train, ds_valid, bs=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lengths = torch.full(size=(BS,), fill_value=D_in, dtype=torch.long)\n",
    "y_lengths = torch.full(size=(BS,), fill_value=D_out_max, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctc_loss = nn.CTCLoss()\n",
    "def ctc_loss_custom(y_pred_b: torch.Tensor, y_b: torch.Tensor) -> float:\n",
    "    if y_pred_lengths.shape[0] != y_pred_b.shape[0]:\n",
    "        new_len = y_pred_b.shape[0]\n",
    "        y_pred_lengths_ = y_pred_lengths[:new_len]\n",
    "        y_lengths_ = y_lengths[:new_len]\n",
    "    else:\n",
    "        y_pred_lengths_ = y_pred_lengths\n",
    "        y_lengths_ = y_lengths\n",
    "    \n",
    "    #print(f'y_pred_b: {y_pred_b.shape}, y_b: {y_b.shape}')\n",
    "    y_pred_b_ = y_pred_b.reshape((y_pred_b.shape[1], y_pred_b.shape[0], C))\n",
    "    #y_b_ = y_b.reshape((y_b.shape[1], y_b.shape[0]))\n",
    "    #print(f'y_pred_b_: {y_pred_b_.shape}, y_b_: {y_b.shape}')\n",
    "    #print(f'y_pred_lengths: {y_pred_lengths.shape}, y_lengths: {y_pred_lengths.shape}')\n",
    "    \n",
    "    return ctc_loss(y_pred_b_, y_b, y_pred_lengths_, y_lengths_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = ctc_loss_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(data, SimpleModel().cuda(), loss_func=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-3.206807</td>\n",
       "      <td>-2.145919</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-1.787082</td>\n",
       "      <td>1.200493</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.486188</td>\n",
       "      <td>1.637264</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.276365</td>\n",
       "      <td>0.811120</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
