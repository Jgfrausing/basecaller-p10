{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from fastai.basics import *\n",
    "\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.utils.files as f\n",
    "import jkbc.types as t\n",
    "import jkbc.utils.loss as jloss\n",
    "import toml\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_out_max = 70\n",
    "C = 5\n",
    "D_out_seq_len = 100\n",
    "BS = 1024\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "model_name = \"bonito-5000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"../../\")\n",
    "path_data = base_dir/\"data\"\n",
    "data_set_name = f'Range0-100-FixLabelLen{D_out_max}'\n",
    "feather_folder = path_data/\"feather-files\"/data_set_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "data_feather = f.read_data_from_feather_file(feather_folder)\n",
    "\n",
    "# Convert to databunch\n",
    "train_dl, valid_dl = prep.convert_to_dataloaders(data_feather, split=.8, batch_size=BS, drop_last=True)\n",
    "data = DataBunch(train_dl, valid_dl, device=DEVICE)\n",
    "del train_dl\n",
    "del valid_dl\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "activations = {\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"leaky_relu\": nn.LeakyReLU,\n",
    "}\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Model template for QuartzNet style architectures\n",
    "\n",
    "    https://arxiv.org/pdf/1910.10261.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.stride = config['block'][0]['stride'][0]\n",
    "        self.alphabet = config['labels']['labels']\n",
    "        self.features = config['block'][-1]['filters']\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(self.features, len(self.alphabet))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.decoder(encoded)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Builds the model encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        features = self.config['input']['features']\n",
    "        activation = activations[self.config['encoder']['activation']]()\n",
    "        encoder_layers = []\n",
    "\n",
    "        for layer in self.config['block']:\n",
    "            encoder_layers.append(\n",
    "                Block(\n",
    "                    features, layer['filters'], activation,\n",
    "                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n",
    "                    stride=layer['stride'], dilation=layer['dilation'],\n",
    "                    dropout=layer['dropout'], residual=layer['residual'],\n",
    "                    separable=layer['separable'],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            features = layer['filters']\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder([x])\n",
    "\n",
    "\n",
    "class TCSConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Time-Channel Separable 1D Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, separable=False):\n",
    "\n",
    "        super(TCSConv1d, self).__init__()\n",
    "        self.separable = separable\n",
    "\n",
    "        if separable:\n",
    "            self.depthwise = nn.Conv1d(\n",
    "                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n",
    "                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n",
    "            )\n",
    "\n",
    "            self.pointwise = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=1, stride=stride,\n",
    "                dilation=dilation, bias=bias, padding=0\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding, dilation=dilation, bias=bias\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.separable:\n",
    "            x = self.depthwise(x)\n",
    "            x = self.pointwise(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    TCSConv, Batch Normalisation, Activation, Dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False):\n",
    "\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.use_res = residual\n",
    "        self.conv = nn.ModuleList()\n",
    "\n",
    "        _in_channels = in_channels\n",
    "        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n",
    "\n",
    "        # add the first n - 1 convolutions + activation\n",
    "        for _ in range(repeat - 1):\n",
    "            self.conv.extend(\n",
    "                self.get_tcs(\n",
    "                    _in_channels, out_channels, kernel_size=kernel_size,\n",
    "                    stride=stride, dilation=dilation,\n",
    "                    padding=padding, separable=separable\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.conv.extend(self.get_activation(activation, dropout))\n",
    "            _in_channels = out_channels\n",
    "\n",
    "        # add the last conv and batch norm\n",
    "        self.conv.extend(\n",
    "            self.get_tcs(\n",
    "                _in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, dilation=dilation,\n",
    "                padding=padding, separable=separable\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # add the residual connection\n",
    "        if self.use_res:\n",
    "            self.residual = nn.Sequential(*self.get_tcs(in_channels, out_channels))\n",
    "\n",
    "        # add the activation and dropout\n",
    "        self.activation = nn.Sequential(*self.get_activation(activation, dropout))\n",
    "\n",
    "    def get_activation(self, activation, dropout):\n",
    "        return activation, nn.Dropout(p=dropout)\n",
    "\n",
    "    def get_padding(self, kernel_size, stride, dilation):\n",
    "        if stride > 1 and dilation > 1:\n",
    "            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n",
    "        return (kernel_size // 2) * dilation\n",
    "\n",
    "    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False):\n",
    "        return [\n",
    "            TCSConv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=stride, dilation=dilation, padding=padding,\n",
    "                bias=bias, separable=separable\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = x[0]\n",
    "        for layer in self.conv:\n",
    "            _x = layer(_x)\n",
    "        if self.use_res:\n",
    "            _x += self.residual(x[0])\n",
    "        return [self.activation(_x)]\n",
    "\n",
    "\n",
    "class Decoder(Module):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, features, classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Conv1d(features, classes, kernel_size=1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x[-1])\n",
    "        return nn.functional.log_softmax(x.transpose(1, 2), dim=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"quartznet5x5.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(config).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model, loss_func=jloss.ctc_loss(D_out_seq_len, BS, C), wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded from: bonito-5000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.load(model_name)\n",
    "    print(f\"Model weights loaded from: {model_name}\")\n",
    "except:\n",
    "    print(\"No weights were loaded..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output size\n",
    "#xb, yb = data.one_batch(); xb = xb.cuda(); y_pred = model(xb); y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='9', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      88.89% [8/9 01:54<00:14]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.537147</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.537084</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.536789</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.537197</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.542228</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.560905</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.565063</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.256651</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='12', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      8.33% [1/12 00:01<00:12 5.0642]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 1.32E-06\n",
      "Min loss divided by 10: 2.29E-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(); learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.537053</td>\n",
       "      <td>1.534068</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 1/100 [00:15<25:11, 15.27s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.536966</td>\n",
       "      <td>1.533981</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 2/100 [00:30<24:52, 15.22s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.536884</td>\n",
       "      <td>1.533898</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 3/100 [00:45<24:42, 15.28s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.536806</td>\n",
       "      <td>1.533821</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 4/100 [01:01<24:32, 15.34s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.536734</td>\n",
       "      <td>1.533746</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 5/100 [01:16<24:20, 15.37s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.536666</td>\n",
       "      <td>1.533677</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 6/100 [01:31<24:00, 15.32s/it]\u001b[A"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='12', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      66.67% [8/12 00:09<00:04 1.5334]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ae816cf67b6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.32e-06\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"smaller\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_detach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/basecaller-p10/jkbc/jkbc/utils/loss.py\u001b[0m in \u001b[0;36m__ctc_loss\u001b[0;34m(y_pred_lengths, alphabet_size, y_pred_b, y_b, y_lengths)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_pred_b_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCTCLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_b_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lengths_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, log_probs, targets, input_lengths, target_lengths)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,\n\u001b[0;32m-> 1295\u001b[0;31m                           self.zero_infinity)\n\u001b[0m\u001b[1;32m   1296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;31m# TODO: L1HingeEmbeddingCriterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mctc_loss\u001b[0;34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[0m\n\u001b[1;32m   1779\u001b[0m     \"\"\"\n\u001b[1;32m   1780\u001b[0m     return torch.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank, _Reduction.get_enum(reduction),\n\u001b[0;32m-> 1781\u001b[0;31m                           zero_infinity)\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(100)):\n",
    "    learn.fit_one_cycle(1, max_lr=1.32e-06)    \n",
    "    learn.save(model_name+\"smaller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 1, 2, 1, 4, 2, 3, 1, 3, 3, 4, 3, 2, 2, 1, 1, 1, 2, 2, 4, 2, 2, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, (y, _) = data.one_batch()\n",
    "y_pred = model(x.to(device=DEVICE)).detach().cpu().numpy()\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "actual = pop.convert_idx_to_base_sequence(y[index])\n",
    "print(actual)\n",
    "for beam in range(25):\n",
    "    decoded = pop.decode(y_pred, threshold=.0, beam_size=beam)   \n",
    "    predicted = decoded[index]\n",
    "    error = pop.calc_sequence_error_metrics(actual, predicted)\n",
    "    print(predicted, beam, error.error)\n",
    "    del predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
