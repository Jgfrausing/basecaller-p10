{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Databunch for Basecalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "\n",
    "import jkbc.utils.experimentation as e\n",
    "import jkbc.utils.files as f\n",
    "import jkbc.utils.loss as l\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK_ID       = pop.BLANK_ID\n",
    "ALPHABET       = pop.ALPHABET # {0: '-', 1: 'A', 2: 'B'}\n",
    "ALPHABET_VAL   = list(ALPHABET.values())\n",
    "ALPHABET_STR   = ''.join(ALPHABET_VAL)\n",
    "ALPHABET_SIZE  = len(ALPHABET_VAL)\n",
    "WINDOW_SIZE    = 300\n",
    "STRIDE         = 300\n",
    "DIMENSIONS_OUT = 70 #Max label len?\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS_PREDICTION_OUT = 100     # DIMENSIONS_OUT*2-1\n",
    "DROP_LAST    = False # SET TO TRUE IF IT FAILS ON LAST BATCH\n",
    "## Add Model specific variables here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 1024  # batch size\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")\n",
    "MODEL_NAME = \"bonito_100_overfit_dropout\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = f'Range0-100-FixLabelLen{DIMENSIONS_OUT}'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "data = f.read_data_from_feather_file(FEATHER_FOLDER)\n",
    "\n",
    "# Convert to databunch\n",
    "train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, drop_last=DROP_LAST)\n",
    "del data\n",
    "databunch = DataBunch(train_dl, valid_dl, device=DEVICE)\n",
    "del train_dl\n",
    "del valid_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = l.ctc_loss(DIMENSIONS_PREDICTION_OUT, BS, ALPHABET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: MAKE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "activations = {\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"leaky_relu\": nn.LeakyReLU,\n",
    "}\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Model template for QuartzNet style architectures\n",
    "\n",
    "    https://arxiv.org/pdf/1910.10261.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.stride = config['block'][0]['stride'][0]\n",
    "        self.alphabet = config['labels']['labels']\n",
    "        self.features = config['block'][-1]['filters']\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(self.features, len(self.alphabet))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.decoder(encoded)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Builds the model encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        features = self.config['input']['features']\n",
    "        activation = activations[self.config['encoder']['activation']]()\n",
    "        encoder_layers = []\n",
    "\n",
    "        for layer in self.config['block']:\n",
    "            encoder_layers.append(\n",
    "                Block(\n",
    "                    features, layer['filters'], activation,\n",
    "                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n",
    "                    stride=layer['stride'], dilation=layer['dilation'],\n",
    "                    dropout=layer['dropout'], residual=layer['residual'],\n",
    "                    separable=layer['separable'],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            features = layer['filters']\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder([x])\n",
    "\n",
    "\n",
    "class TCSConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Time-Channel Separable 1D Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, separable=False):\n",
    "\n",
    "        super(TCSConv1d, self).__init__()\n",
    "        self.separable = separable\n",
    "\n",
    "        if separable:\n",
    "            self.depthwise = nn.Conv1d(\n",
    "                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n",
    "                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n",
    "            )\n",
    "\n",
    "            self.pointwise = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=1, stride=stride,\n",
    "                dilation=dilation, bias=bias, padding=0\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding, dilation=dilation, bias=bias\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.separable:\n",
    "            x = self.depthwise(x)\n",
    "            x = self.pointwise(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    TCSConv, Batch Normalisation, Activation, Dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False):\n",
    "\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.use_res = residual\n",
    "        self.conv = nn.ModuleList()\n",
    "\n",
    "        _in_channels = in_channels\n",
    "        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n",
    "\n",
    "        # add the first n - 1 convolutions + activation\n",
    "        for _ in range(repeat - 1):\n",
    "            self.conv.extend(\n",
    "                self.get_tcs(\n",
    "                    _in_channels, out_channels, kernel_size=kernel_size,\n",
    "                    stride=stride, dilation=dilation,\n",
    "                    padding=padding, separable=separable\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.conv.extend(self.get_activation(activation, dropout))\n",
    "            _in_channels = out_channels\n",
    "\n",
    "        # add the last conv and batch norm\n",
    "        self.conv.extend(\n",
    "            self.get_tcs(\n",
    "                _in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, dilation=dilation,\n",
    "                padding=padding, separable=separable\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # add the residual connection\n",
    "        if self.use_res:\n",
    "            self.residual = nn.Sequential(*self.get_tcs(in_channels, out_channels))\n",
    "\n",
    "        # add the activation and dropout\n",
    "        self.activation = nn.Sequential(*self.get_activation(activation, dropout))\n",
    "\n",
    "    def get_activation(self, activation, dropout):\n",
    "        return activation, nn.Dropout(p=dropout)\n",
    "\n",
    "    def get_padding(self, kernel_size, stride, dilation):\n",
    "        if stride > 1 and dilation > 1:\n",
    "            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n",
    "        return (kernel_size // 2) * dilation\n",
    "\n",
    "    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False):\n",
    "        return [\n",
    "            TCSConv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=stride, dilation=dilation, padding=padding,\n",
    "                bias=bias, separable=separable\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = x[0]\n",
    "        for layer in self.conv:\n",
    "            _x = layer(_x)\n",
    "        if self.use_res:\n",
    "            _x += self.residual(x[0])\n",
    "        return [self.activation(_x)]\n",
    "\n",
    "\n",
    "class Decoder(Module):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, features, classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Conv1d(features, classes, kernel_size=1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x[-1])\n",
    "        return nn.functional.log_softmax(x.transpose(1, 2), dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"quartznet5x5.toml\")\n",
    "for b in config['block']:\n",
    "    b['dropout'] = DROPOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(config).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(databunch, model, loss_func=loss_func, path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights available\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learner = learner.load(MODEL_NAME)\n",
    "    print('Model weights loaded')\n",
    "except:\n",
    "    print('No model weights available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      87.50% [7/8 01:47<00:15]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.683024</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.679894</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.643451</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.190687</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.752269</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.419363</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.200907</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      61.54% [8/13 00:09<00:05 2.0896]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 5.75E-04\n",
      "Min loss divided by 10: 3.31E-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.629193</td>\n",
       "      <td>3.380390</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.542353</td>\n",
       "      <td>3.222339</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.375453</td>\n",
       "      <td>2.661295</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.067780</td>\n",
       "      <td>1.637514</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.678396</td>\n",
       "      <td>1.838518</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.361804</td>\n",
       "      <td>1.685454</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.163586</td>\n",
       "      <td>1.607173</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.008552</td>\n",
       "      <td>2.148596</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.895013</td>\n",
       "      <td>2.487809</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.811264</td>\n",
       "      <td>2.098696</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.748973</td>\n",
       "      <td>2.194538</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.702427</td>\n",
       "      <td>2.286332</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.667387</td>\n",
       "      <td>2.282262</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.641080</td>\n",
       "      <td>2.226068</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.621140</td>\n",
       "      <td>2.129853</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.606099</td>\n",
       "      <td>2.091129</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.594795</td>\n",
       "      <td>2.068989</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.586284</td>\n",
       "      <td>2.045483</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.579789</td>\n",
       "      <td>1.983824</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.574661</td>\n",
       "      <td>1.884846</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.570514</td>\n",
       "      <td>1.733866</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.566830</td>\n",
       "      <td>1.704445</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.563792</td>\n",
       "      <td>1.674561</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.561020</td>\n",
       "      <td>1.703709</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.558514</td>\n",
       "      <td>1.652826</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.556134</td>\n",
       "      <td>1.654886</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.553895</td>\n",
       "      <td>1.611402</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.551738</td>\n",
       "      <td>1.592036</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.549796</td>\n",
       "      <td>1.574206</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.547995</td>\n",
       "      <td>1.560720</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.546278</td>\n",
       "      <td>1.553732</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.544856</td>\n",
       "      <td>1.548373</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.543664</td>\n",
       "      <td>1.543966</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.542933</td>\n",
       "      <td>1.541476</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.542728</td>\n",
       "      <td>1.540047</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.543228</td>\n",
       "      <td>1.539504</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.543539</td>\n",
       "      <td>1.539575</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.543001</td>\n",
       "      <td>1.539504</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.541978</td>\n",
       "      <td>1.539533</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.541217</td>\n",
       "      <td>1.539428</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.540565</td>\n",
       "      <td>1.539319</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.540031</td>\n",
       "      <td>1.539334</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.539547</td>\n",
       "      <td>1.539349</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.539120</td>\n",
       "      <td>1.539346</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.538768</td>\n",
       "      <td>1.539271</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.538508</td>\n",
       "      <td>1.539233</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.538227</td>\n",
       "      <td>1.539220</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.537954</td>\n",
       "      <td>1.539220</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.537775</td>\n",
       "      <td>1.539199</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.537582</td>\n",
       "      <td>1.539174</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.537473</td>\n",
       "      <td>1.539134</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.537345</td>\n",
       "      <td>1.539112</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.537258</td>\n",
       "      <td>1.539094</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.537190</td>\n",
       "      <td>1.539076</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.537091</td>\n",
       "      <td>1.539075</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.536955</td>\n",
       "      <td>1.539086</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.536896</td>\n",
       "      <td>1.539100</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.536828</td>\n",
       "      <td>1.539107</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.536799</td>\n",
       "      <td>1.539112</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.536758</td>\n",
       "      <td>1.539114</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.536700</td>\n",
       "      <td>1.539112</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.536642</td>\n",
       "      <td>1.539115</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.536627</td>\n",
       "      <td>1.539113</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit_one_cycle(63, max_lr=learner.recorder.min_grad_lr) # It was best after 63 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(MODEL_NAME+\"_T=0.358\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, (y, _) = databunch.one_batch()\n",
    "x_device = x.to(device=DEVICE)\n",
    "y_pred = model(x_device).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DIMENSIONS_PREDICTION_OUT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7349d8bbd379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDIMENSIONS_PREDICTION_OUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIMENSIONS_PREDICTION_OUT\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Range can't contain values larger than PRED_OUT_DIM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_idx_to_base_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mALPHABET_VAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DIMENSIONS_PREDICTION_OUT' is not defined"
     ]
    }
   ],
   "source": [
    "r = range(min(5, DIMENSIONS_PREDICTION_OUT), min(DIMENSIONS_PREDICTION_OUT+1, 50)) #Range can't contain values larger than PRED_OUT_DIM\n",
    "\n",
    "for index in [0, BS//2, BS-1]:\n",
    "    actual = pop.convert_idx_to_base_sequence(y[index], ALPHABET_VAL)\n",
    "    prediction = y_pred[index]\n",
    "    for pred, beam, error in e.get_stats(prediction, actual, ALPHABET_STR, r):\n",
    "        print(pred, beam, error.error)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run assemble only if data is not fetched from featherfile\n",
    "# TODO: Assembled should not be on a batch, but instead on a complete signal\n",
    "if STRIDE != WINDOW_SIZE:\n",
    "    decoded = pop.decode(y_pred, ALPHABET_STR, beam_size=15)\n",
    "    assembled = pop.assemble(decoded, WINDOW_SIZE, STRIDE, ALPHABET)\n",
    "    print('Assembled:', assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
