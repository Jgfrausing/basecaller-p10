{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Databunch for Basecalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "\n",
    "import jkbc.utils.experimentation as e\n",
    "import jkbc.utils.files as f\n",
    "import jkbc.utils.loss as l\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import toml\n",
    "import bonito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK_ID       = pop.BLANK_ID\n",
    "ALPHABET       = pop.ALPHABET # {0: '-', 1: 'A', 2: 'B'}\n",
    "ALPHABET_VAL   = list(ALPHABET.values())\n",
    "ALPHABET_STR   = ''.join(ALPHABET_VAL)\n",
    "ALPHABET_SIZE  = len(ALPHABET_VAL)\n",
    "WINDOW_SIZE    = 300\n",
    "STRIDE         = 300\n",
    "DIMENSIONS_OUT = 70 #Max label len?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS_PREDICTION_OUT = 100     # DIMENSIONS_OUT*2-1\n",
    "DROP_LAST    = False # SET TO TRUE IF IT FAILS ON LAST BATCH\n",
    "## Add Model specific variables here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 1024  # batch size\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")\n",
    "MODEL_NAME = \"bonito_pretrained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = f'Range0-100-FixLabelLen{DIMENSIONS_OUT}'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "data = f.read_data_from_feather_file(FEATHER_FOLDER)\n",
    "\n",
    "# Convert to databunch\n",
    "train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, drop_last=DROP_LAST)\n",
    "del data\n",
    "databunch = DataBunch(train_dl, valid_dl, device=DEVICE)\n",
    "del train_dl\n",
    "del valid_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = l.ctc_loss(DIMENSIONS_PREDICTION_OUT, BS, ALPHABET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: MAKE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "activations = {\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"leaky_relu\": nn.LeakyReLU,\n",
    "}\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Model template for QuartzNet style architectures\n",
    "\n",
    "    https://arxiv.org/pdf/1910.10261.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.stride = config['block'][0]['stride'][0]\n",
    "        self.alphabet = config['labels']['labels']\n",
    "        self.features = config['block'][-1]['filters']\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(self.features, len(self.alphabet))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.decoder(encoded)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Builds the model encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        features = self.config['input']['features']\n",
    "        activation = activations[self.config['encoder']['activation']]()\n",
    "        encoder_layers = []\n",
    "\n",
    "        for layer in self.config['block']:\n",
    "            encoder_layers.append(\n",
    "                Block(\n",
    "                    features, layer['filters'], activation,\n",
    "                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n",
    "                    stride=layer['stride'], dilation=layer['dilation'],\n",
    "                    dropout=layer['dropout'], residual=layer['residual'],\n",
    "                    separable=layer['separable'],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            features = layer['filters']\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder([x])\n",
    "\n",
    "\n",
    "class TCSConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Time-Channel Separable 1D Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, separable=False):\n",
    "\n",
    "        super(TCSConv1d, self).__init__()\n",
    "        self.separable = separable\n",
    "\n",
    "        if separable:\n",
    "            self.depthwise = nn.Conv1d(\n",
    "                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n",
    "                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n",
    "            )\n",
    "\n",
    "            self.pointwise = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=1, stride=stride,\n",
    "                dilation=dilation, bias=bias, padding=0\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding, dilation=dilation, bias=bias\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.separable:\n",
    "            x = self.depthwise(x)\n",
    "            x = self.pointwise(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    TCSConv, Batch Normalisation, Activation, Dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False):\n",
    "\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.use_res = residual\n",
    "        self.conv = nn.ModuleList()\n",
    "\n",
    "        _in_channels = in_channels\n",
    "        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n",
    "\n",
    "        # add the first n - 1 convolutions + activation\n",
    "        for _ in range(repeat - 1):\n",
    "            self.conv.extend(\n",
    "                self.get_tcs(\n",
    "                    _in_channels, out_channels, kernel_size=kernel_size,\n",
    "                    stride=stride, dilation=dilation,\n",
    "                    padding=padding, separable=separable\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.conv.extend(self.get_activation(activation, dropout))\n",
    "            _in_channels = out_channels\n",
    "\n",
    "        # add the last conv and batch norm\n",
    "        self.conv.extend(\n",
    "            self.get_tcs(\n",
    "                _in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, dilation=dilation,\n",
    "                padding=padding, separable=separable\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # add the residual connection\n",
    "        if self.use_res:\n",
    "            self.residual = nn.Sequential(*self.get_tcs(in_channels, out_channels))\n",
    "\n",
    "        # add the activation and dropout\n",
    "        self.activation = nn.Sequential(*self.get_activation(activation, dropout))\n",
    "\n",
    "    def get_activation(self, activation, dropout):\n",
    "        return activation, nn.Dropout(p=dropout)\n",
    "\n",
    "    def get_padding(self, kernel_size, stride, dilation):\n",
    "        if stride > 1 and dilation > 1:\n",
    "            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n",
    "        return (kernel_size // 2) * dilation\n",
    "\n",
    "    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False):\n",
    "        return [\n",
    "            TCSConv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=stride, dilation=dilation, padding=padding,\n",
    "                bias=bias, separable=separable\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = x[0]\n",
    "        for layer in self.conv:\n",
    "            _x = layer(_x)\n",
    "        if self.use_res:\n",
    "            _x += self.residual(x[0])\n",
    "        return [self.activation(_x)]\n",
    "\n",
    "\n",
    "class Decoder(Module):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, features, classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Conv1d(features, classes, kernel_size=1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x[-1])\n",
    "        return nn.functional.log_softmax(x.transpose(1, 2), dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"quartznet5x5.toml\")\n",
    "model = Model(config).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"models/weights_1.tar\", map_location=DEVICE)\n",
    "\n",
    "# These lines come from bonito/utils\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k.replace('module.', '')\n",
    "    new_state_dict[name] = v\n",
    "    \n",
    "model.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(databunch, model, loss_func=loss_func, path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"try:\\n    learner = learner.load(MODEL_NAME)\\n    print(f'Model weights loaded for: {MODEL_NAME}')\\nexcept:\\n    print('No model weights available')\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''try:\n",
    "    learner = learner.load(MODEL_NAME)\n",
    "    print(f'Model weights loaded for: {MODEL_NAME}')\n",
    "except:\n",
    "    print('No model weights available')''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='8', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/8 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/13 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 31.72 GiB total capacity; 8.48 GiB already allocated; 23.38 MiB free; 8.50 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-da3593d87630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuggestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-061a832d00be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-061a832d00be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-061a832d00be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0m_x\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-061a832d00be>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepthwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 31.72 GiB total capacity; 8.48 GiB already allocated; 23.38 MiB free; 8.50 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.fit_one_cycle(500, max_lr=learner.recorder.min_grad_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Bonito Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonito_data_path = \"../../../bonito/bonito/data\"\n",
    "#data = bonito.util.load_data(directory=bonito_data_path)\n",
    "chunks, chunk_lengths, targets, target_lengths = bonito.util.load_data(limit=1, directory=bonito_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'), dtype('uint16'), dtype('uint8'), dtype('uint16'))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks.dtype, chunk_lengths.dtype, targets.dtype, target_lengths.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0065521644"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks, chunk_lengths, targets, target_lengths = map(np.array, (chunks, chunk_lengths, targets, target_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = bonito.training.ChunkDataSet(chunks, chunk_lengths, targets, target_lengths)\n",
    "dataloader = DataLoader(testdata, batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, out_lengths, target, lengths) in enumerate(dataloader, start=1):\n",
    "        \n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        log_probs = model(data).detach().cpu().numpy()\n",
    "        \n",
    "        results += (batch_idx, data, out_lengths, target, lengths, log_probs)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx, data, out_lengths, target, lengths, log_probs = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 4800]),\n",
       " tensor([3636], dtype=torch.int32),\n",
       " torch.Size([1, 400]),\n",
       " tensor([381], dtype=torch.int32),\n",
       " (1, 1600, 5))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, out_lengths, target.shape, lengths, log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pop.convert_idx_to_base_sequence(target[0], ALPHABET_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.062224, -5.97276 , -3.035085, -4.946698, -5.951125],\n",
       "        [-0.102751, -2.736266, -3.465993, -6.86299 , -7.507209],\n",
       "        [-5.453623, -0.055677, -6.383053, -3.077139, -6.168561],\n",
       "        [-0.783411, -1.047214, -9.657618, -1.649778, -9.381308],\n",
       "        ...,\n",
       "        [-0.283705, -3.178688, -2.230607, -2.763137, -3.357722],\n",
       "        [-0.806489, -1.805606, -1.309533, -2.429527, -3.468034],\n",
       "        [-1.087876, -1.382959, -1.275261, -2.255162, -3.574876],\n",
       "        [-0.760871, -1.140428, -1.86716 , -3.175094, -4.091978]]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = log_probs; prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1600, 5)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_maxed = prediction.argmax(dim=2)\n",
    "pred_maxed.shape\n",
    "pred_maxed_list = list(pred_maxed.view((1600,)))\n",
    "pred_maxed_list_int = list(map(int, pred_maxed_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_str = \"\".join([ALPHABET[x] for x in pred_maxed_list_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCAAAAGTATTTTCGAGAATCTTACTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGAAACAGCTGCCAAAACTGGTATGATTGCATGGTTTCGGTGAATTACCACAGTGGCGCGGGTGCGGCTGGTTTGGCGGC'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_clean = pop.__remove_duplicates_and_blanks(predicted_str); pred_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AGGAGATCTTGATTTCTTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTTCTACAAAGTATTTTCGAGAATCTTGCTTCTGCCCCTTTTTTCTTTTTTTAAAAGGTTTAAAAAACATAACTGTCTTCAATATATCCAGTATTTACGACAATATACAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGATGCTATTTTGGACGCTTGTTTAGAACAAGATCCATTCTCCAAGGTTGCCTGTGAAACAGCTGCCAAAACTGGTATGATTATGGTTTTCGGTGAAATTACCACCAAAGCT'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005249343832021025"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop.calc_sequence_error_metrics(actual, pred_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 381)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_clean), len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGAGATCTTGATTTCTTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTTCTACAAAGTATTTTCGAGAATCTTGCTTCTGCCCCTTTTTTCTTTTTTTAAAAGGTTTAAAAAACATAACTGTCTTCAATATATCCAGTATTTACGACAATATACAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGATGCTATTTTGGACGCTTGTTTAGAACAAGATCCATTCTCCAAGGTTGCCTGTGAAACAGCTGCCAAAACTGGTATGATTATGGTTTTCGGTGAAATTACCACCAAAGCT\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGCGGGTGCGGGCGCTGGTTTGAGCGGGGCA 5 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCCCGCGGGTGCGGGCGCTGGTTTGAGCGGGGCA 6 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGCGCTGGTTGTGAGCGGGCCA 7 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCCGCGGGTGCGGCGCTGGTTGTGGGCGGGCCA 8 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGCCA 9 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGCGGGTGCGGGCGCTGGTTGTGGGCGGGCCA 10 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGCCA 11 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGCCA 12 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGCCA 13 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 14 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 15 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 16 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 17 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 18 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 19 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 20 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 21 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 22 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 23 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 24 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 25 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCA 26 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCGCA 27 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCGCA 28 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCGCA 29 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCCGCGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCGCA 30 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCGCA 31 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCCGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 32 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 33 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 34 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 35 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCCGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 36 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 37 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 38 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 39 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 40 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCCGGTGCGGGCGCTGGTTGTGGGCGGGGGCA 41 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGGCA 42 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGGCA 43 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 44 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGCCA 45 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCCGGTGCGGGCGCTGGTTGTGGGCGGGGGCA 46 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCCGGTGCGGGCGCTGGTTGTGGGCGGGGGCA 47 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGCGCCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGGCA 48 0.994750656167979\n",
      "AGAGATGTGATTTCTTTTGGTAGTCATCTGTCGTCTTGAGGCGTATAAGAAGGAGGTTATATCTGTCCTTCTCTAAAAGTATTTTCGAGAATCTTCTTCTGCCCCTTTTTTCTTTTTTAAGGATTTTAAAAAGCATAACTGTCTTCAATATATCCAGTATTTACGACAATAGCAAACATAATCATGTCCAAGAGCAAAACTTTCTTATTTACCTCTGAATCCGTCGGTGAAGGTCACCCAGACAAGATTTGTGACCAAGTTTCTGTGCTATTTTGGACGCTTGTTTAGAACGAATCCATTCTCCAAGGTTGCCTGTGGAAACAGCTGCCAAAACTGGTATGATTGCTGGTTTCGGTGAATTACCCAGCTGGGCGCCGGCGGGTGCGGGCGCTGGTTGTGGGCGGGGGCA 49 0.994750656167979\n"
     ]
    }
   ],
   "source": [
    "r = range(min(5, DIMENSIONS_PREDICTION_OUT), min(DIMENSIONS_PREDICTION_OUT+1, 50))\n",
    "for pred, beam, error in e.get_stats(prediction[0], actual, ALPHABET_STR, r):\n",
    "    print(pred, beam, error.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGACATCGAGGTGCCAAACCTCC\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 5 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 6 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 7 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 8 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 9 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 10 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 11 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 12 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 13 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 14 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 15 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 16 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 17 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 18 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 19 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 20 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 21 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 22 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 23 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 24 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 25 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 26 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 27 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 28 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 29 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 30 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 31 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 32 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 33 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 34 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 35 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 36 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 37 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 38 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 39 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 40 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 41 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 42 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 43 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 44 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 45 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 46 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 47 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 48 0.6956521739130435\n",
      "GGCTGTCGAGTGCCGCAGAGCATA 49 0.6956521739130435\n",
      "\n",
      "AGATGATTCGTCTAATGTCGTCCTTTG\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 5 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 6 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 7 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 8 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 9 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 10 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 11 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 12 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 13 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 14 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 15 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 16 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 17 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 18 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 19 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 20 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 21 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 22 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 23 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 24 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 25 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 26 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 27 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 28 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 29 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 30 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 31 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 32 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 33 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 34 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 35 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 36 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 37 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 38 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 39 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 40 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 41 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 42 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 43 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 44 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 45 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 46 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 47 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 48 0.5555555555555556\n",
      "CAAATAATTAAATACAATAATGTCCTTTA 49 0.5555555555555556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = range(min(5, DIMENSIONS_PREDICTION_OUT), min(DIMENSIONS_PREDICTION_OUT+1, 50)) #Range can't contain values larger than PRED_OUT_DIM\n",
    "\n",
    "for index in [0, BS-1]:\n",
    "    actual = pop.convert_idx_to_base_sequence(y[index], ALPHABET_VAL)\n",
    "    prediction = y_pred[index]\n",
    "    for pred, beam, error in e.get_stats(prediction, actual, ALPHABET_STR, r):\n",
    "        print(pred, beam, error.error)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembled: G-G-GGGGC-GACAGGGGCGCAGGCCGCGCG--C-CC--GG-CAC-G-GGG---\n"
     ]
    }
   ],
   "source": [
    "# Run assemble only if data is not fetched from featherfile\n",
    "# TODO: Assembled should not be on a batch, but instead on a complete signal\n",
    "if STRIDE-1 != WINDOW_SIZE:\n",
    "    decoded = pop.decode(y_pred, ALPHABET_STR, beam_size=15)\n",
    "    assembled = pop.assemble(decoded, WINDOW_SIZE, STRIDE, ALPHABET)\n",
    "    print('Assembled:', assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
