{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Like Bonito\n",
    "https://github.com/nanoporetech/bonito/blob/master/notebooks/bonito-train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bonito'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0eae7b652924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCosineAnnealingLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbonito\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbonito\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbonito\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChunkDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bonito'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from itertools import starmap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.files.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from bonito.model import Model\n",
    "from bonito.util import accuracy\n",
    "from bonito.training import ChunkDataSet\n",
    "from bonito.decode import decode, decode_ref\n",
    "\n",
    "import jkbc.files.torch_files as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of squiggle that correspond with the target reference sequence\n",
    "data = f.load_training_data('/basecaller-p10/data/feather-files/Range0-10000-FixLabelLen1024-winsize4096')\n",
    "\n",
    "full_chunks = load_np(\"chunks.npy\")\n",
    "full_chunk_lengths = load_np(\"chunk_lengths.npy\")\n",
    "full_targets = load_np(\"references.npy\")\n",
    "full_target_lengths = load_np(\"reference_lengths.npy\")\n",
    "\n",
    "print(full_chunks.shape)\n",
    "full_chunks = data.x\n",
    "full_chunk_lengths = data.x_lengths\n",
    "full_targets = data.y\n",
    "full_target_lengths = data.y_lengths\n",
    "\n",
    "# The structure of the model is defined using a config file.\n",
    "# This will make sense to those familar with QuartzNet\n",
    "# https://arxiv.org/pdf/1910.10261.pdf).\n",
    "quartznet_config = toml.load(\"../models/bonito/quartznet5x5.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training options\n",
    "Default options are set, and ranges are sensible, but most combinations of settings are untested.\n",
    "\n",
    "The default settings will train on a small amount of data (1000 signal chunks) for a small number of epochs (20). This is unlikely to produce an accurate generalisable model, but will train relatively quickly.\n",
    "\n",
    "After modifying this cell, Runtime -> Run after, so that all cells between this one and the main train looping will be run in accordance with new setting.\n",
    "\n",
    "A train_proportion of 0.90 will use 90% of the data for training and 10% for validation.\n",
    "\n",
    "No dropout is applied by default, but in order to avoid overfitting on small data sets it may be necessary to apply dropout (e.g. of 0.5), or other regularisation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_savepath = Path(\"train_like_bonito/models\")\n",
    "learning_rate = 0.001 #@param {type:\"number\"}\n",
    "random_seed = 25 #@param {type:\"integer\"}\n",
    "epochs = 20 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
    "batch_size = 16 #@param [2, 4, 8, 16, 28] {type:\"raw\"}\n",
    "num_chunks = 10000 #@param [10, 100, 1000, 10000, 100000] {type:\"raw\"}\n",
    "train_proportion = 0.80 #@param type:\"slider\", min:0.8, max:1000, step:1\n",
    "dropout = 0.0 #@param {type:\"slider\", min:0.0, max:0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random libs and setup cudnn\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# we exploit GPU for training\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data according to values set in the 'Training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset\n",
    "chunks = full_chunks[:num_chunks]\n",
    "chunk_lengths = full_chunk_lengths[:num_chunks]\n",
    "targets = full_targets[:num_chunks]\n",
    "target_lengths = full_target_lengths[:num_chunks]\n",
    "\n",
    "# shuffle\n",
    "shuf = np.random.permutation(chunks.shape[0])\n",
    "chunks = chunks[shuf]\n",
    "chunk_lengths = chunk_lengths[shuf]\n",
    "targets = targets[shuf]\n",
    "target_lengths = target_lengths[shuf]\n",
    "\n",
    "split = np.floor(chunks.shape[0] * train_proportion).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'QuartzNet',\n",
       " 'labels': {'labels': ['N', 'A', 'C', 'G', 'T']},\n",
       " 'input': {'features': 1},\n",
       " 'encoder': {'activation': 'relu'},\n",
       " 'block': [{'filters': 256,\n",
       "   'repeat': 1,\n",
       "   'kernel': [33],\n",
       "   'stride': [3],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': False,\n",
       "   'separable': False},\n",
       "  {'filters': 256,\n",
       "   'repeat': 5,\n",
       "   'kernel': [33],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 256,\n",
       "   'repeat': 5,\n",
       "   'kernel': [39],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 5,\n",
       "   'kernel': [51],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 5,\n",
       "   'kernel': [63],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 5,\n",
       "   'kernel': [75],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 1,\n",
       "   'kernel': [87],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': False,\n",
       "   'separable': True},\n",
       "  {'filters': 1024,\n",
       "   'repeat': 1,\n",
       "   'kernel': [1],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': False,\n",
       "   'separable': False}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for b in quartznet_config['block']:\n",
    "    b['dropout'] = dropout\n",
    "quartznet_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'Connectionist Temporal Classification' (CTC) loss fuction\n",
    "# https://distill.pub/2017/ctc/\n",
    "criterion = nn.CTCLoss(reduction='mean')\n",
    "\n",
    "def train(log_interval, model, device, train_loader,\n",
    "          optimizer, epoch, use_amp=False):\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    chunks = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    sys.stderr.write(\"\\n\" + \"Training epoch: \" + str(epoch) + \"\\n\")\n",
    "    progress_bar = tqdm(total=len(train_loader), leave=True, ncols=100)\n",
    "\n",
    "    for batch_idx, (data, out_lengths, target, lengths) in enumerate(train_loader, start=1):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        chunks += data.shape[0]\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        log_probs = model(data)    \n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(log_probs.transpose(0, 1), target, out_lengths / model.stride, lengths)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        progress_bar.refresh()\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(\"Loss: \" + str(loss.item()))\n",
    "        sys.stderr.flush()        \n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    return loss.item(), time.perf_counter() - t0\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    prediction_lengths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, out_lengths, target, lengths) in enumerate(test_loader, start=1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    " \n",
    "            # forward pass\n",
    "            log_probs = model(data)\n",
    " \n",
    "            # calculate loss\n",
    "            test_loss += criterion(log_probs.transpose(1, 0), target, out_lengths / model.stride, lengths)\n",
    "\n",
    "            # accumulate output probabilities\n",
    "            predictions.append(torch.exp(log_probs).cpu())\n",
    "            prediction_lengths.append(out_lengths / model.stride)\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    lengths = np.concatenate(prediction_lengths)\n",
    "\n",
    "    # convert probabilities to sequences\n",
    "    references = [decode_ref(target, model.alphabet) for target in test_loader.dataset.targets]\n",
    "    sequences = [decode(post[:n], model.alphabet) for post, n in zip(predictions, lengths)]\n",
    "\n",
    "    # align predicted sequences with true sequences and calculate accuracy\n",
    "    if all(map(len, sequences)):\n",
    "        accuracies = list(starmap(accuracy, zip(references, sequences)))\n",
    "    else:\n",
    "        accuracies = [0]\n",
    "\n",
    "    # measure average accuracies over entire set of validation chunks\n",
    "    mean = np.mean(accuracies)\n",
    "    median = np.median(accuracies)\n",
    "\n",
    "    return test_loss.item() / batch_idx, mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set experiment name\n",
    "experiment_name = 'bonito_on_our_data_007' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_uniformise_(model):\n",
    "    for l in model.modules():\n",
    "        if isinstance(l, nn.Conv1d):\n",
    "            nn.init.kaiming_uniform_(l.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 1\n",
      "Loss: 0.7485458850860596: 100%|███████████████████████████████████| 500/500 [01:50<00:00,  4.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_mean</th>\n",
       "      <th>validation_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 12:31:53.621902</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.748546</td>\n",
       "      <td>0.751881</td>\n",
       "      <td>73.506264</td>\n",
       "      <td>73.592311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  duration  epoch  train_loss  validation_loss  \\\n",
       "0 2020-04-07 12:31:53.621902       110      1    0.748546         0.751881   \n",
       "\n",
       "   validation_mean  validation_median  \n",
       "0        73.506264          73.592311  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 2\n",
      "Loss: 0.4637991189956665: 100%|███████████████████████████████████| 500/500 [01:50<00:00,  4.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_mean</th>\n",
       "      <th>validation_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 12:33:52.519944</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0.463799</td>\n",
       "      <td>0.50625</td>\n",
       "      <td>83.730111</td>\n",
       "      <td>83.879781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  duration  epoch  train_loss  validation_loss  \\\n",
       "0 2020-04-07 12:33:52.519944       110      2    0.463799          0.50625   \n",
       "\n",
       "   validation_mean  validation_median  \n",
       "0        83.730111          83.879781  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 3\n",
      "Loss: 0.38080522418022156: 100%|██████████████████████████████████| 500/500 [01:50<00:00,  4.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_mean</th>\n",
       "      <th>validation_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 12:35:51.410513</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0.380805</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>87.808241</td>\n",
       "      <td>88.307072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  duration  epoch  train_loss  validation_loss  \\\n",
       "0 2020-04-07 12:35:51.410513       110      3    0.380805         0.386206   \n",
       "\n",
       "   validation_mean  validation_median  \n",
       "0        87.808241          88.307072  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 4\n",
      "Loss: 0.24445544183254242: 100%|██████████████████████████████████| 500/500 [01:50<00:00,  4.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_mean</th>\n",
       "      <th>validation_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 12:37:50.279766</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>0.244455</td>\n",
       "      <td>0.332215</td>\n",
       "      <td>89.54865</td>\n",
       "      <td>90.080487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  duration  epoch  train_loss  validation_loss  \\\n",
       "0 2020-04-07 12:37:50.279766       110      4    0.244455         0.332215   \n",
       "\n",
       "   validation_mean  validation_median  \n",
       "0         89.54865          90.080487  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 5\n",
      "Loss: 0.2506150007247925: 100%|███████████████████████████████████| 500/500 [01:50<00:00,  4.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_mean</th>\n",
       "      <th>validation_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 12:39:49.127182</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250615</td>\n",
       "      <td>0.287588</td>\n",
       "      <td>91.296989</td>\n",
       "      <td>91.884058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  duration  epoch  train_loss  validation_loss  \\\n",
       "0 2020-04-07 12:39:49.127182       110      5    0.250615         0.287588   \n",
       "\n",
       "   validation_mean  validation_median  \n",
       "0        91.296989          91.884058  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 6\n",
      "Loss: 0.17058908939361572: 100%|██████████████████████████████████| 500/500 [01:50<00:00,  4.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_mean</th>\n",
       "      <th>validation_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 12:41:47.953550</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>0.170589</td>\n",
       "      <td>0.260316</td>\n",
       "      <td>92.265061</td>\n",
       "      <td>92.878338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  duration  epoch  train_loss  validation_loss  \\\n",
       "0 2020-04-07 12:41:47.953550       110      6    0.170589         0.260316   \n",
       "\n",
       "   validation_mean  validation_median  \n",
       "0        92.265061          92.878338  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 7\n",
      "Loss: 0.19782748818397522: 100%|██████████████████████████████████| 500/500 [01:50<00:00,  4.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_mean</th>\n",
       "      <th>validation_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-07 12:43:47.059304</td>\n",
       "      <td>110</td>\n",
       "      <td>7</td>\n",
       "      <td>0.197827</td>\n",
       "      <td>0.254359</td>\n",
       "      <td>92.58659</td>\n",
       "      <td>93.133047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  duration  epoch  train_loss  validation_loss  \\\n",
       "0 2020-04-07 12:43:47.059304       110      7    0.197827         0.254359   \n",
       "\n",
       "   validation_mean  validation_median  \n",
       "0         92.58659          93.133047  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 8\n",
      "Loss: 0.15273253619670868:  51%|█████████████████▍                | 256/500 [00:56<00:53,  4.52it/s]"
     ]
    }
   ],
   "source": [
    "# prevent overwriting of data\n",
    "workdir = os.path.join(model_savepath, experiment_name)\n",
    "if os.path.isdir(workdir):\n",
    "    raise IOError('{} already exists. Select an alternative model_savepath.'.format(workdir))\n",
    "os.makedirs(workdir)\n",
    "\n",
    "# data generators\n",
    "train_dataset = ChunkDataSet(chunks[:split], chunk_lengths[:split],\n",
    "                             targets[:split], target_lengths[:split])\n",
    "test_dataset = ChunkDataSet(chunks[split:], chunk_lengths[split:],\n",
    "                            targets[split:], target_lengths[split:])\n",
    "\n",
    "# data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                         num_workers=4, pin_memory=True)\n",
    "\n",
    "# load bonito model\n",
    "model = Model(quartznet_config)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# set optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), amsgrad=True, lr=learning_rate)\n",
    "schedular = CosineAnnealingLR(optimizer, epochs * len(train_loader))\n",
    "\n",
    "# report loss every \n",
    "interval = 500 / num_chunks\n",
    "log_interval = np.floor(len(train_dataset) / batch_size * interval)\n",
    "\n",
    "exp_config = os.path.join(workdir, \"experimental.log\")\n",
    "with open(exp_config, 'a') as c:\n",
    "    c.write('Num training chunks: {}'.format(num_chunks) + '\\n')\n",
    "    c.write('learning rate: {}'.format(learning_rate) + '\\n')\n",
    "    c.write('random seed: {}'.format(random_seed) + '\\n')\n",
    "    c.write('epochs: {}'.format(epochs) + '\\n')\n",
    "    c.write('batch_size: {}'.format(batch_size) + '\\n')\n",
    "    c.write('train proportion: {}'.format(train_proportion) + '\\n')\n",
    "    c.write('dropout: {}'.format(dropout) + '\\n')\n",
    "\n",
    "# DataFrame to store training logging information\n",
    "training_results = pd.DataFrame()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    train_loss, duration = train(log_interval, model, device,\n",
    "                                 train_loader, optimizer, epoch)\n",
    "    \n",
    "    test_loss, mean, median = test(model, device, test_loader)\n",
    "\n",
    "    # collate training and validation metrics\n",
    "    epoch_result = pd.DataFrame(\n",
    "        {'time':[datetime.today()],\n",
    "         'duration':[int(duration)],\n",
    "         'epoch':[epoch],\n",
    "         'train_loss':[train_loss],\n",
    "         'validation_loss':[test_loss], \n",
    "         'validation_mean':[mean],\n",
    "         'validation_median':[median]})\n",
    "    \n",
    "    # save model weights\n",
    "    weights_path = os.path.join(workdir, \"weights_%s.tar\" % epoch)\n",
    "    torch.save(model.state_dict(), weights_path)\n",
    "\n",
    "    # update log file\n",
    "    log_path = os.path.join(workdir, \"training.log\")\n",
    "    epoch_result.to_csv(log_path, mode='a', sep='\\t', index=False)\n",
    "\n",
    "    display(epoch_result)\n",
    "    training_results = training_results.append(epoch_result)\n",
    "\n",
    "    schedular.step()\n",
    "\n",
    "display(training_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tries (after 1 epoch): \n",
    "\n",
    "With Kaiming:\n",
    "\n",
    "1: 0.9324800968170166\n",
    "\n",
    "2: 0.9282790422439575\n",
    "\n",
    "Without Kaiming:\n",
    "\n",
    "1: 0.7507233619689941\n",
    "\n",
    "Without Kaiming, dropout=0.5:\n",
    "\n",
    "1: 1.2488034963607788\n",
    "\n",
    "I am unsure why the runs differ with same settings when we use seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
