{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set these\n",
    "f1 = \"./../../taiyakiOutputs/output_createfasta.hdf5\"\n",
    "f2 = \"./../../taiyakiOutputs/output_justfromfasta.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reads_dict(filename):\n",
    "    file = h5py.File(filename, \"r\")\n",
    "    file = file['Reads']\n",
    "    reads = []\n",
    "    for r in file.keys():\n",
    "        elem = {}\n",
    "        elem['UUID'] = r\n",
    "        for k in file[r].keys():\n",
    "            elem[k]=file[r][k][()]\n",
    "        reads.append(elem)\n",
    "    return reads\n",
    "\n",
    "def normalise_list(lst):\n",
    "    mmin = min(lst)\n",
    "    mmax = max(lst)\n",
    "    lst = (lst - mmin)/(mmax - mmin)\n",
    "    return lst\n",
    "\n",
    "def are_signals_equal(s1,s2):\n",
    "    if(len(s1) != len(s2)):\n",
    "        return False\n",
    "\n",
    "    are_equal = True\n",
    "    for idx, val in enumerate(s1):\n",
    "        if(s1[idx] != s2[idx]):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def find_matches_in_tayiaki_ouput(mapped_reads, unmapped_reads):\n",
    "    matched = []\n",
    "    unmatched = []\n",
    "\n",
    "    for r1 in mapped_reads:\n",
    "        s1 = r1['Dacs']\n",
    "        found = None\n",
    "        for r2 in unmapped_reads:\n",
    "            s2 = r2['Dacs']\n",
    "            if(are_signals_equal(s1,s2)):\n",
    "                found = r2\n",
    "        if(found != None):\n",
    "            matched.append([r1,found])\n",
    "        else:\n",
    "            unmatched.append(r1)\n",
    "    \n",
    "    return matched, unmatched\n",
    "\n",
    "def load_reads(f1,f2):\n",
    "    unmapped_reads = get_reads_dict(f1)\n",
    "    mapped_reads = get_reads_dict(f2)\n",
    "    \n",
    "    return find_matches_in_tayiaki_ouput(mapped_reads, unmapped_reads)\n",
    "\n",
    "def get_read_attributes(read):\n",
    "    #id, signal, points, labels\n",
    "    return read['UUID'], normalise_list(read['Dacs']), read['Ref_to_signal'], read['Reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_reads_percent(f1, f2):\n",
    "    reads, other_reads = load_reads(f1,f2)\n",
    "    return f\"Mapping to reference caused the loss of {100 - (len(other_reads) / len(reads) * 100)}% of data\"\n",
    "\n",
    "print(get_matched_reads_percent(f1,f2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ctc_test] *",
   "language": "python",
   "name": "conda-env-ctc_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
