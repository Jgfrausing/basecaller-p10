{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Like Bonito\n",
    "https://github.com/nanoporetech/bonito/blob/master/notebooks/bonito-train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from itertools import starmap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from bonito.util import accuracy\n",
    "from bonito.training import ChunkDataSet\n",
    "from bonito.decode import decode, decode_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  mapped_reads.hdf5\n"
     ]
    }
   ],
   "source": [
    "!cd ../../../mapped_reads/bonito_preprocessed/; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"../../../mapped_reads/bonito_preprocessed/\")\n",
    "def load_np(fn): return np.load(base_dir/'data'/fn)\n",
    "#def load_toml(fn): return toml.load(base_dir/'config'/fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sections of squiggle that correspond with the target reference sequence\n",
    "# Variable length and zero padded (upto 4096 samples).\n",
    "# shape (1000000, 4096)\n",
    "# dtype('float32')\n",
    "full_chunks = load_np(\"chunks.npy\")\n",
    "\n",
    "# Lengths of squiggle sections in chunks.npy \n",
    "# shape (1000000,)\n",
    "# dtype('uint16')\n",
    "full_chunk_lengths = load_np(\"chunk_lengths.npy\")\n",
    "\n",
    "# Integer encoded target sequence {'A': 1, 'C': 2, 'G': 3, 'T': 4}\n",
    "# Variable length and zero padded (default range between 128 and 256).\n",
    "# shape (1000000, 256)\n",
    "# dtype('uint8')\n",
    "full_targets = load_np(\"references.npy\")\n",
    "\n",
    "# Lengths of target sequences in references.npy\n",
    "# shape (1000000,)\n",
    "# dtype('uint8')\n",
    "full_target_lengths = load_np(\"reference_lengths.npy\")\n",
    "\n",
    "# The structure of the model is defined using a config file.\n",
    "# This will make sense to those familar with QuartzNet\n",
    "# https://arxiv.org/pdf/1910.10261.pdf).\n",
    "quartznet_config = toml.load(\"../models/quartznet5x5.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ReLU, LeakyReLU, GELU\n",
    "from torch.nn import Module, ModuleList, Sequential, Conv1d, BatchNorm1d, Dropout\n",
    "\n",
    "activations = {\n",
    "    \"relu\": ReLU,\n",
    "    \"leaky_relu\": LeakyReLU,\n",
    "    \"gelu\": GELU,\n",
    "}\n",
    "\n",
    "\n",
    "class Model(Module):\n",
    "    \"\"\"\n",
    "    Model template for QuartzNet style architectures\n",
    "\n",
    "    https://arxiv.org/pdf/1910.10261.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.stride = config['block'][0]['stride'][0]\n",
    "        self.alphabet = config['labels']['labels']\n",
    "        self.features = config['block'][-1]['filters']\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(self.features, len(self.alphabet))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.decoder(encoded)\n",
    "\n",
    "\n",
    "class Encoder(Module):\n",
    "    \"\"\"\n",
    "    Builds the model encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        features = self.config['input']['features']\n",
    "        activation = activations[self.config['encoder']['activation']]()\n",
    "        encoder_layers = []\n",
    "\n",
    "        for layer in self.config['block']:\n",
    "            encoder_layers.append(\n",
    "                Block(\n",
    "                    features, layer['filters'], activation,\n",
    "                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n",
    "                    stride=layer['stride'], dilation=layer['dilation'],\n",
    "                    dropout=layer['dropout'], residual=layer['residual'],\n",
    "                    separable=layer['separable'],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            features = layer['filters']\n",
    "\n",
    "        self.encoder = Sequential(*encoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder([x])\n",
    "\n",
    "\n",
    "class TCSConv1d(Module):\n",
    "    \"\"\"\n",
    "    Time-Channel Separable 1D Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, separable=False):\n",
    "\n",
    "        super(TCSConv1d, self).__init__()\n",
    "        self.separable = separable\n",
    "        self.groups = groups\n",
    "        #if groups > 1 and not separable:\n",
    "            #raise ValueError(\"Grouping should probably only be used with separable kernels.\")\n",
    "\n",
    "        if separable:\n",
    "            self.depthwise = Conv1d(\n",
    "                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n",
    "                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n",
    "            )\n",
    "\n",
    "            self.pointwise = Conv1d(\n",
    "                in_channels, out_channels, kernel_size=1, stride=stride,\n",
    "                dilation=dilation, bias=bias, padding=0, groups=groups\n",
    "            )\n",
    "        else:\n",
    "            self.conv = Conv1d(\n",
    "                in_channels, out_channels, kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding, dilation=dilation, bias=bias, groups=groups\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.separable:\n",
    "            x = self.depthwise(x)\n",
    "            x = self.pointwise(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "        if self.groups > 1:\n",
    "                x = channel_shuffle(x, self.groups)\n",
    "        return x\n",
    "      \n",
    "def channel_shuffle(x, groups):\n",
    "    # type: (torch.Tensor, int) -> torch.Tensor\n",
    "    batchsize, num_channels, feature_count = x.data.size()\n",
    "    channels_per_group = num_channels // groups\n",
    "\n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups,\n",
    "               channels_per_group, feature_count)\n",
    "\n",
    "    x = torch.transpose(x, 1, 2).contiguous()\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, feature_count)\n",
    "\n",
    "    return x\n",
    "\n",
    "class Block(Module):\n",
    "    \"\"\"\n",
    "    TCSConv, Batch Normalisation, Activation, Dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False):\n",
    "\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.use_res = residual\n",
    "        self.conv = ModuleList()\n",
    "        \n",
    "        self.groups = 4 if separable else 1\n",
    "\n",
    "        _in_channels = in_channels\n",
    "        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n",
    "\n",
    "        # add the first n - 1 convolutions + activation\n",
    "        for _ in range(repeat - 1):\n",
    "            self.conv.extend(\n",
    "                self.get_tcs(\n",
    "                    _in_channels, out_channels, kernel_size=kernel_size,\n",
    "                    stride=stride, dilation=dilation,\n",
    "                    padding=padding, separable=separable, groups=self.groups\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.conv.extend(self.get_activation(activation, dropout))\n",
    "            _in_channels = out_channels\n",
    "\n",
    "        # add the last conv and batch norm\n",
    "        self.conv.extend(\n",
    "            self.get_tcs(\n",
    "                _in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, dilation=dilation,\n",
    "                padding=padding, separable=separable, groups=self.groups\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # add the residual connection\n",
    "        if self.use_res:\n",
    "            self.residual = Sequential(*self.get_tcs(in_channels, out_channels))\n",
    "\n",
    "        # add the activation and dropout\n",
    "        self.activation = Sequential(*self.get_activation(activation, dropout))\n",
    "\n",
    "    def get_activation(self, activation, dropout):\n",
    "        return activation, Dropout(p=dropout)\n",
    "\n",
    "    def get_padding(self, kernel_size, stride, dilation):\n",
    "        if stride > 1 and dilation > 1:\n",
    "            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n",
    "        return (kernel_size // 2) * dilation\n",
    "\n",
    "    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False, groups=1):\n",
    "        return [\n",
    "            TCSConv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=stride, dilation=dilation, padding=padding,\n",
    "                bias=bias, separable=separable, groups=groups\n",
    "            ),\n",
    "            BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = x[0]\n",
    "        for layer in self.conv:\n",
    "            _x = layer(_x)\n",
    "        if self.use_res:\n",
    "            _x += self.residual(x[0])\n",
    "        return [self.activation(_x)]\n",
    "\n",
    "\n",
    "class Decoder(Module):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, features, classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = Sequential(Conv1d(features, classes, kernel_size=1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x[-1])\n",
    "        return nn.functional.log_softmax(x.transpose(1, 2), dim=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training options\n",
    "Default options are set, and ranges are sensible, but most combinations of settings are untested.\n",
    "\n",
    "The default settings will train on a small amount of data (1000 signal chunks) for a small number of epochs (20). This is unlikely to produce an accurate generalisable model, but will train relatively quickly.\n",
    "\n",
    "After modifying this cell, Runtime -> Run after, so that all cells between this one and the main train looping will be run in accordance with new setting.\n",
    "\n",
    "A train_proportion of 0.90 will use 90% of the data for training and 10% for validation.\n",
    "\n",
    "No dropout is applied by default, but in order to avoid overfitting on small data sets it may be necessary to apply dropout (e.g. of 0.5), or other regularisation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_savepath = Path(\"train_like_bonito/models\")\n",
    "learning_rate = 0.001 #@param {type:\"number\"}\n",
    "random_seed = 25 #@param {type:\"integer\"}\n",
    "epochs = 20 #@param {type:\"slider\", min:1, max:1000, step:1}\n",
    "batch_size = 16 #@param [2, 4, 8, 16, 28] {type:\"raw\"}\n",
    "num_chunks = 10000 #@param [10, 100, 1000, 10000, 100000] {type:\"raw\"}\n",
    "train_proportion = 0.80 #@param type:\"slider\", min:0.8, max:1000, step:1\n",
    "dropout = 0.0 #@param {type:\"slider\", min:0.0, max:0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random libs and setup cudnn\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# we exploit GPU for training\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data according to values set in the 'Training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset\n",
    "chunks = full_chunks[:num_chunks]\n",
    "chunk_lengths = full_chunk_lengths[:num_chunks]\n",
    "targets = full_targets[:num_chunks]\n",
    "target_lengths = full_target_lengths[:num_chunks]\n",
    "\n",
    "# shuffle\n",
    "shuf = np.random.permutation(chunks.shape[0])\n",
    "chunks = chunks[shuf]\n",
    "chunk_lengths = chunk_lengths[shuf]\n",
    "targets = targets[shuf]\n",
    "target_lengths = target_lengths[shuf]\n",
    "\n",
    "split = np.floor(chunks.shape[0] * train_proportion).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'QuartzNet',\n",
       " 'name': 'bonito',\n",
       " 'pred_out_scale': 3,\n",
       " 'labels': {'labels': ['N', 'A', 'C', 'G', 'T']},\n",
       " 'input': {'features': 1},\n",
       " 'encoder': {'activation': 'relu'},\n",
       " 'block': [{'filters': 256,\n",
       "   'repeat': 1,\n",
       "   'kernel': [33],\n",
       "   'stride': [3],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': False,\n",
       "   'separable': False},\n",
       "  {'filters': 256,\n",
       "   'repeat': 5,\n",
       "   'kernel': [33],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 256,\n",
       "   'repeat': 5,\n",
       "   'kernel': [39],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 5,\n",
       "   'kernel': [51],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 5,\n",
       "   'kernel': [63],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 5,\n",
       "   'kernel': [75],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': True,\n",
       "   'separable': True},\n",
       "  {'filters': 512,\n",
       "   'repeat': 1,\n",
       "   'kernel': [87],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': False,\n",
       "   'separable': True},\n",
       "  {'filters': 1024,\n",
       "   'repeat': 1,\n",
       "   'kernel': [1],\n",
       "   'stride': [1],\n",
       "   'dilation': [1],\n",
       "   'dropout': 0.0,\n",
       "   'residual': False,\n",
       "   'separable': False}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for b in quartznet_config['block']:\n",
    "    b['dropout'] = dropout\n",
    "quartznet_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'Connectionist Temporal Classification' (CTC) loss fuction\n",
    "# https://distill.pub/2017/ctc/\n",
    "criterion = nn.CTCLoss(reduction='mean')\n",
    "\n",
    "def train(log_interval, model, device, train_loader,\n",
    "          optimizer, epoch, use_amp=False):\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    chunks = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    sys.stderr.write(\"\\n\" + \"Training epoch: \" + str(epoch) + \"\\n\")\n",
    "    progress_bar = tqdm(total=len(train_loader), leave=True, ncols=100)\n",
    "\n",
    "    for batch_idx, (data, out_lengths, target, lengths) in enumerate(train_loader, start=1):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        chunks += data.shape[0]\n",
    "\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        log_probs = model(data)    \n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(log_probs.transpose(0, 1), target, out_lengths / model.stride, lengths)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        progress_bar.refresh()\n",
    "        progress_bar.update(1)\n",
    "        progress_bar.set_description(\"Loss: \" + str(loss.item()))\n",
    "        sys.stderr.flush()        \n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    return loss.item(), time.perf_counter() - t0\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    prediction_lengths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, out_lengths, target, lengths) in enumerate(test_loader, start=1):\n",
    "            data, target = data.to(device), target.to(device)\n",
    " \n",
    "            # forward pass\n",
    "            log_probs = model(data)\n",
    " \n",
    "            # calculate loss\n",
    "            test_loss += criterion(log_probs.transpose(1, 0), target, out_lengths / model.stride, lengths)\n",
    "\n",
    "            # accumulate output probabilities\n",
    "            predictions.append(torch.exp(log_probs).cpu())\n",
    "            prediction_lengths.append(out_lengths / model.stride)\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    lengths = np.concatenate(prediction_lengths)\n",
    "\n",
    "    # convert probabilities to sequences\n",
    "    references = [decode_ref(target, model.alphabet) for target in test_loader.dataset.targets]\n",
    "    sequences = [decode(post[:n], model.alphabet) for post, n in zip(predictions, lengths)]\n",
    "\n",
    "    # align predicted sequences with true sequences and calculate accuracy\n",
    "    if all(map(len, sequences)):\n",
    "        accuracies = list(starmap(accuracy, zip(references, sequences)))\n",
    "    else:\n",
    "        accuracies = [0]\n",
    "\n",
    "    # measure average accuracies over entire set of validation chunks\n",
    "    mean = np.mean(accuracies)\n",
    "    median = np.median(accuracies)\n",
    "\n",
    "    return test_loss.item() / batch_idx, mean, median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Set experiment name\n",
    "experiment_name = 'bonito_groups_11' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_uniformise_(model):\n",
    "    for l in model.modules():\n",
    "        if isinstance(l, nn.Conv1d):\n",
    "            nn.init.kaiming_uniform_(l.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training epoch: 1\n",
      "Loss: 0.9193114042282104:  72%|█████████████████████████▏         | 360/500 [01:08<00:26,  5.34it/s]"
     ]
    }
   ],
   "source": [
    "# prevent overwriting of data\n",
    "workdir = os.path.join(model_savepath, experiment_name)\n",
    "if os.path.isdir(workdir):\n",
    "    raise IOError('{} already exists. Select an alternative model_savepath.'.format(workdir))\n",
    "os.makedirs(workdir)\n",
    "\n",
    "# data generators\n",
    "train_dataset = ChunkDataSet(chunks[:split], chunk_lengths[:split],\n",
    "                             targets[:split], target_lengths[:split])\n",
    "test_dataset = ChunkDataSet(chunks[split:], chunk_lengths[split:],\n",
    "                            targets[split:], target_lengths[split:])\n",
    "\n",
    "# data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                         num_workers=4, pin_memory=True)\n",
    "\n",
    "# load bonito model\n",
    "model = Model(quartznet_config)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# set optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), amsgrad=True, lr=learning_rate)\n",
    "schedular = CosineAnnealingLR(optimizer, epochs * len(train_loader))\n",
    "\n",
    "# report loss every \n",
    "interval = 500 / num_chunks\n",
    "log_interval = np.floor(len(train_dataset) / batch_size * interval)\n",
    "\n",
    "exp_config = os.path.join(workdir, \"experimental.log\")\n",
    "with open(exp_config, 'a') as c:\n",
    "    c.write('Num training chunks: {}'.format(num_chunks) + '\\n')\n",
    "    c.write('learning rate: {}'.format(learning_rate) + '\\n')\n",
    "    c.write('random seed: {}'.format(random_seed) + '\\n')\n",
    "    c.write('epochs: {}'.format(epochs) + '\\n')\n",
    "    c.write('batch_size: {}'.format(batch_size) + '\\n')\n",
    "    c.write('train proportion: {}'.format(train_proportion) + '\\n')\n",
    "    c.write('dropout: {}'.format(dropout) + '\\n')\n",
    "\n",
    "# DataFrame to store training logging information\n",
    "training_results = pd.DataFrame()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    train_loss, duration = train(log_interval, model, device,\n",
    "                                 train_loader, optimizer, epoch)\n",
    "    \n",
    "    test_loss, mean, median = test(model, device, test_loader)\n",
    "\n",
    "    # collate training and validation metrics\n",
    "    epoch_result = pd.DataFrame(\n",
    "        {'time':[datetime.today()],\n",
    "         'duration':[int(duration)],\n",
    "         'epoch':[epoch],\n",
    "         'train_loss':[train_loss],\n",
    "         'validation_loss':[test_loss], \n",
    "         'validation_mean':[mean],\n",
    "         'validation_median':[median]})\n",
    "    \n",
    "    # save model weights\n",
    "    weights_path = os.path.join(workdir, \"weights_%s.tar\" % epoch)\n",
    "    torch.save(model.state_dict(), weights_path)\n",
    "\n",
    "    # update log file\n",
    "    log_path = os.path.join(workdir, \"training.log\")\n",
    "    epoch_result.to_csv(log_path, mode='a', sep='\\t', index=False)\n",
    "\n",
    "    display(epoch_result)\n",
    "    training_results = training_results.append(epoch_result)\n",
    "\n",
    "    schedular.step()\n",
    "\n",
    "display(training_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tries (after 1 epoch): \n",
    "\n",
    "With Kaiming:\n",
    "\n",
    "1: 0.9324800968170166\n",
    "\n",
    "2: 0.9282790422439575\n",
    "\n",
    "Without Kaiming:\n",
    "\n",
    "1: 0.7507233619689941\n",
    "\n",
    "Without Kaiming, dropout=0.5:\n",
    "\n",
    "1: 1.2488034963607788\n",
    "\n",
    "I am unsure why the runs differ with same settings when we use seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separable are grouped in 4\n",
    "Loss: 0.7064507007598877: 100%|███████████████████████████████████| 500/500 [01:38<00:00,  5.15it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4024325"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groups = 4\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not grouped:\n",
    "Loss: 0.7371149063110352: 100%|███████████████████████████████████| 500/500 [01:50<00:00,  4.56it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6678533"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groups = 1\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
