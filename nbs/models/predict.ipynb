{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "import json\n",
    "\n",
    "import jkbc.model as m\n",
    "import jkbc.model.factory as factory\n",
    "import jkbc.utils.constants as constants\n",
    "import jkbc.utils.torch_files as f\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.utils.fasta as fasta\n",
    "\n",
    "import jkbc.utils.kd as kd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = 'Range0-50-FixLabelLen400-winsize4096'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET\n",
    "\n",
    "with open(FEATHER_FOLDER/'config.json', 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "ALPHABET       = constants.ALPHABET\n",
    "ALPHABET_VAL   = list(ALPHABET.values())\n",
    "ALPHABET_STR   = ''.join(ALPHABET_VAL)\n",
    "ALPHABET_SIZE  = len(ALPHABET.keys())\n",
    "WINDOW_SIZE    = int(config['maxw']) #maxw = max windowsize\n",
    "DIMENSIONS_OUT = int(config['maxl']) # maxl = max label length\n",
    "MIN_LABEL_LEN  = int(config['minl']) # maxl = max label length\n",
    "STRIDE         = WINDOW_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3  # default learning rate\n",
    "BS = 2**3  # batch size\n",
    "EPOCHS = 400\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS_PREDICTION_OUT = WINDOW_SIZE//3+1\n",
    "DROP_LAST = False # SET TO TRUE IF IT FAILS ON LAST BATCH\n",
    "model, MODEL_NAME = factory.bonito(DEVICE, BASE_DIR)\n",
    "MODEL_NAME = f'{MODEL_NAME}'\n",
    "MODEL_DIR = f'{MODEL_NAME}/weights'\n",
    "model_weights = 'bestmodel_8'\n",
    "predicter = m.get_predicter(model, MODEL_DIR, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not model_weights:\n",
    "    model_weights = m.get_newest_model(MODEL_DIR)\n",
    "\n",
    "predicter.load(model_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save teacher output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "data = f.load_training_data(FEATHER_FOLDER) \n",
    "kd.generate_and_save_y_teacher(FEATHER_FOLDER, MODEL_NAME, m.signal_to_input_tensor(data.x, DEVICE), predicter.model, bs=BS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = prep.SignalCollection(BASE_DIR/constants.MAPPED_READS, labels_per_window=(MIN_LABEL_LEN,DIMENSIONS_OUT), \n",
    "                           stride=STRIDE, window_size=(WINDOW_SIZE-1, WINDOW_SIZE), blank_id=constants.BLANK_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:41,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Skipping index 33119 (probably because it was empty)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:15<00:12,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Skipping index 420565 (probably because it was empty)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:38<00:01,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Skipping index 65986 (probably because it was empty)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:39<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# predict range\n",
    "predict_objects = m.predict_range(predicter.model, sc, ALPHABET_STR, WINDOW_SIZE, DEVICE, indexes=np.random.randint(0, len(sc), 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 1771.49it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 5426.01it/s]\n",
      "11it [00:00, 1419.44it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 3819.00it/s]\n",
      "12it [00:00, 1719.15it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 4136.05it/s]\n",
      "8it [00:00, 1445.25it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 3484.73it/s]\n",
      "12it [00:00, 1893.09it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 4151.41it/s]\n",
      "9it [00:00, 1670.15it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 3647.93it/s]\n",
      "1it [00:00, 625.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2392.64it/s]\n",
      "13it [00:00, 1795.80it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 5419.00it/s]\n",
      "13it [00:00, 2032.58it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 4257.51it/s]\n",
      "14it [00:00, 2061.73it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 5235.87it/s]\n",
      "12it [00:00, 1814.54it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 3821.11it/s]\n",
      "14it [00:00, 2005.95it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 5437.56it/s]\n",
      "1it [00:00, 571.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1277.58it/s]\n",
      "7it [00:00, 1673.04it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 3108.87it/s]\n",
      "7it [00:00, 1593.93it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 3214.73it/s]\n",
      "10it [00:00, 1815.87it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 3914.79it/s]\n",
      "5it [00:00, 1539.99it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2821.79it/s]\n",
      "11it [00:00, 1844.68it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 6280.61it/s]\n",
      "3it [00:00, 1303.79it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 4476.31it/s]\n",
      "1it [00:00, 774.71it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1663.09it/s]\n",
      "5it [00:00, 1572.90it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 3225.40it/s]\n",
      "14it [00:00, 2099.85it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 5366.50it/s]\n",
      "14it [00:00, 1881.46it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 4368.42it/s]\n",
      "12it [00:00, 1903.55it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 4184.19it/s]\n",
      "9it [00:00, 1746.49it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 6006.16it/s]\n",
      "7it [00:00, 1446.38it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 4019.18it/s]\n",
      "12it [00:00, 1874.62it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 6506.16it/s]\n",
      "12it [00:00, 2013.19it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 4136.39it/s]\n",
      "12it [00:00, 1720.80it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 4805.39it/s]\n",
      "12it [00:00, 1899.38it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 6014.06it/s]\n",
      "9it [00:00, 1558.13it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 5980.47it/s]\n",
      "13it [00:00, 1843.46it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 4328.83it/s]\n",
      "5it [00:00, 1263.04it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 5477.02it/s]\n",
      "9it [00:00, 1569.01it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 3950.27it/s]\n",
      "11it [00:00, 1878.94it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 5321.49it/s]\n",
      "11it [00:00, 1777.45it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 3990.77it/s]\n",
      "1it [00:00, 1401.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1721.80it/s]\n",
      "5it [00:00, 1563.76it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 2679.38it/s]\n",
      "11it [00:00, 1811.23it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 6503.71it/s]\n",
      "13it [00:00, 1885.73it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 4470.44it/s]\n",
      "12it [00:00, 1760.22it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 4207.63it/s]\n",
      "15it [00:00, 2106.14it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 4956.24it/s]\n",
      "12it [00:00, 1709.52it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 5260.96it/s]\n",
      "13it [00:00, 2044.39it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 3610.75it/s]\n",
      "11it [00:00, 1795.65it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 6608.99it/s]\n",
      "9it [00:00, 1638.12it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 3750.12it/s]\n",
      "10it [00:00, 1783.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 3829.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8892272517231213"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert outputs to dictionaries\n",
    "references = []\n",
    "predictions = []\n",
    "accuracies = []\n",
    "for po in predict_objects:\n",
    "    [accuracies.append(a) for a in m.get_accuracies(po.references, po.predictions, ALPHABET_VAL)]\n",
    "    ref, pred = fasta.map_decoded(po, ALPHABET_VAL, False)\n",
    "    references.append(ref)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Sanity tjek\n",
    "np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dicts ready to be saved\n",
    "ref_dict = fasta.merge(references)\n",
    "pred_dict = fasta.merge(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dicts\n",
    "fasta.save_dicts(pred_dict, ref_dict, f'{MODEL_NAME}/predictions/{DATA_SET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
