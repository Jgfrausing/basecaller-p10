{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jkbc.model as m\n",
    "import jkbc.utils.constants as constants\n",
    "import jkbc.utils.torch_files as f\n",
    "import jkbc.utils.general as g\n",
    "import jkbc.utils.metrics as metric\n",
    "import jkbc.utils.preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random libs and setup cudnn\n",
    "random_seed = 25 # MAGIC!!\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = 'Range0-10000-FixLabelLen400-winsize4096'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET\n",
    "\n",
    "with open(FEATHER_FOLDER/'config.json', 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "ALPHABET       = constants.ALPHABET\n",
    "ALPHABET_SIZE  = len(ALPHABET.keys())\n",
    "WINDOW_SIZE    = int(config['maxw']) #maxw = max windowsize\n",
    "DIMENSIONS_OUT = int(config['maxl']) # maxl = max label length\n",
    "STRIDE         = WINDOW_SIZE\n",
    "\n",
    "KNOWLEGDE_DISTILLATION = False\n",
    "TEACHER_OUTPUT = 'bonito-pretrained-Valid[3.625368118286133]-CTC[90.3227304562121]' # Set to name of y_teacher output\n",
    "if KNOWLEGDE_DISTILLATION and not TEACHER_OUTPUT:\n",
    "    print('WARNING! Must provide name of teacher output when doing knowledge distillation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3  # default learning rate\n",
    "BS = 2^11  # batch size\n",
    "EPOCHS = 1000\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bonito_basic as model_file\n",
    "DIMENSIONS_PREDICTION_OUT = WINDOW_SIZE//3+1\n",
    "DROP_LAST = False # SET TO TRUE IF IT FAILS ON LAST BATCH\n",
    "model, MODEL_NAME = model_file.model(DEVICE, WINDOW_SIZE, DIMENSIONS_PREDICTION_OUT)\n",
    "MODEL_NAME = f'{MODEL_NAME}-windowsize={WINDOW_SIZE}'\n",
    "MODEL_DIR = f'weights/{MODEL_NAME}'\n",
    "SPECIFIC_MODEL_WEIGHTS = None #'bonito-pretrained-Valid[1.545677900314331]-CTC[91.66666666666667]' #Set to specific name of model ('None' uses the newest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, metrics and callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ctc_loss = metric.CtcLoss(WINDOW_SIZE, DIMENSIONS_PREDICTION_OUT, BS, ALPHABET_SIZE)\n",
    "_kd_loss = metric.KdLoss(alpha=.3, temperature=5, label_loss=_ctc_loss)\n",
    "LOSS_FUNC = _kd_loss.loss() if KNOWLEGDE_DISTILLATION else _ctc_loss.loss()\n",
    "#LOSS_FUNC = nn.CTCLoss()\n",
    "METRICS = []#[metric.ctc_accuracy(ALPHABET, 5)]\n",
    "SAVE_CALLBACK = partial(metric.SaveModelCallback, every='epoch', monitor='valid_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "data = f.load_training_data(FEATHER_FOLDER) \n",
    "\n",
    "# Convert to databunch\n",
    "train_dl, valid_dl = prep.convert_to_dataloaders(data, split=1, batch_size=BS, drop_last=DROP_LAST, windows=10000)\n",
    "databunch = DataBunch(train_dl, valid_dl, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(databunch, model, loss_func=LOSS_FUNC, model_dir=MODEL_DIR, metrics=METRICS, opt_func=AdamW(model.parameters(), amsgrad=True, lr=LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_model_weights(learner, SPECIFIC_MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default to LR if lr_find() has not been run\n",
    "try: lr = learner.recorder.min_grad_lr\n",
    "except: lr = LR\n",
    "lr = LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(10, lr=lr, callbacks=[SAVE_CALLBACK(learner)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = prep.SignalCollection(BASE_DIR/constants.MAPPED_READS, training_data=False, stride=1, window_size=(WINDOW_SIZE-1, WINDOW_SIZE), blank_id=constants.BLANK_ID)\n",
    "validate_signal_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index in range(validate_signal_count): \n",
    "# Get read object (signal and reference)\n",
    "read_object = sc[0]\n",
    "# Predict signals\n",
    "x = read_object.x\n",
    "x_size= len(x)\n",
    "outputs = []\n",
    "x = torch.tensor(read_object.x, dtype=torch.float32)\n",
    "for from_ in tqdm(range(0, x_size, 100)):\n",
    "    to = min(x_size-1, from_+100)\n",
    "    x_ = m.signal_to_input_tensor(x[from_:to], DEVICE)\n",
    "    outputs += learner.model(x_).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled, (accuracy, alignment) = m.predict(learner, outputs, ALPHABET, WINDOW_SIZE, 1, read_object.reference, beam_size=500, beam_threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
