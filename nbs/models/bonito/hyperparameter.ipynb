{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jkbc.model as m\n",
    "import jkbc.utils.constants as constants\n",
    "import jkbc.utils.torch_files as f\n",
    "import jkbc.utils.general as g\n",
    "import jkbc.utils.metrics as metric\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.utils.fasta as fasta\n",
    "import jkbc.model.schedulers as schedulers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random libs and setup cudnn\n",
    "random_seed = 25 # MAGIC!!\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = 'Range0-50-FixLabelLen400-winsize4096'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET\n",
    "\n",
    "with open(FEATHER_FOLDER/'config.json', 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "ALPHABET       = constants.ALPHABET\n",
    "ALPHABET_VAL   = list(ALPHABET.values())\n",
    "ALPHABET_STR   = ''.join(ALPHABET_VAL)\n",
    "ALPHABET_SIZE  = len(ALPHABET.keys())\n",
    "WINDOW_SIZE    = int(config['maxw']) #maxw = max windowsize\n",
    "DIMENSIONS_OUT = int(config['maxl']) # maxl = max label length\n",
    "STRIDE         = WINDOW_SIZE\n",
    "\n",
    "KNOWLEGDE_DISTILLATION = True\n",
    "TEACHER_OUTPUT = 'bonito-csv' # Set to name of y_teacher output\n",
    "if KNOWLEGDE_DISTILLATION and not TEACHER_OUTPUT:\n",
    "    print('WARNING! Must provide name of teacher output when doing knowledge distillation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [metric.ctc_accuracy(ALPHABET, 5)]\n",
    "SAVE_CALLBACK = partial(metric.SaveModelCallback, every='epoch', monitor='valid_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3  # default learning rate\n",
    "BS = 2**6  # batch size\n",
    "EPOCHS = 5\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bonito_basic as model_file\n",
    "DIMENSIONS_PREDICTION_OUT = WINDOW_SIZE//3+1\n",
    "DROP_LAST = False # SET TO TRUE IF IT FAILS ON LAST BATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "if KNOWLEGDE_DISTILLATION:\n",
    "    data, teacher = f.load_training_data_with_teacher(FEATHER_FOLDER, TEACHER_OUTPUT)\n",
    "    train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, teacher=teacher, drop_last=DROP_LAST)\n",
    "else:\n",
    "    data = f.load_training_data(FEATHER_FOLDER) \n",
    "    train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, drop_last=DROP_LAST)\n",
    "\n",
    "# Convert to databunch\n",
    "databunch = DataBunch(train_dl, valid_dl, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ctc_loss = metric.CtcLoss(WINDOW_SIZE, DIMENSIONS_PREDICTION_OUT, BS, ALPHABET_SIZE)\n",
    "\n",
    "loss_funcs = {}\n",
    "for t in [1,2,4,8,16,32]:\n",
    "    for a in np.arange(0,1.1,.1):\n",
    "        loss_funcs[f't={t},a={a}'] = metric.KdLoss(alpha=a, temperature=t, label_loss=_ctc_loss).loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {'AdamW': partial(torch.optim.AdamW, amsgrad=True, lr=LR)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "moms = [0.8, 0.9]; cycles = [3, 5, 7, 9]\n",
    "named_schedulers = schedulers.get_named_schedulers(EPOCHS, LR, moms, cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>ctc_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.738150</td>\n",
       "      <td>2.309319</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.490978</td>\n",
       "      <td>1.365939</td>\n",
       "      <td>0.568710</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.363995</td>\n",
       "      <td>1.286394</td>\n",
       "      <td>0.582772</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.255742</td>\n",
       "      <td>1.188579</td>\n",
       "      <td>0.585535</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.147161</td>\n",
       "      <td>1.168314</td>\n",
       "      <td>0.590121</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'fastai.callbacks' has no attribute 'Scheduler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-53fc8d895cca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ms_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattach_scheduler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnamed_schedulers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mattach_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0;31m# FIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/basecaller-p10/jkbc/jkbc/model/schedulers.py\u001b[0m in \u001b[0;36mattach_annealing_cos_scheduler\u001b[0;34m(learner, epochs, min_lr, max_lr)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                    min_lr: float, max_lr: float) -> None:\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mremove_all_schedulers_from_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtotal_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_total_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/basecaller-p10/jkbc/jkbc/model/schedulers.py\u001b[0m in \u001b[0;36mremove_all_schedulers_from_learner\u001b[0;34m(learner)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_all_schedulers_from_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     learner.callbacks = list(filter(lambda cb: not isinstance(\n\u001b[0;32m---> 98\u001b[0;31m         cb, (fcbs.GeneralScheduler, fcbs.Scheduler)), learner.callbacks))\n\u001b[0m",
      "\u001b[0;32m~/basecaller-p10/jkbc/jkbc/model/schedulers.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(cb)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_all_schedulers_from_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     learner.callbacks = list(filter(lambda cb: not isinstance(\n\u001b[0;32m---> 98\u001b[0;31m         cb, (fcbs.GeneralScheduler, fcbs.Scheduler)), learner.callbacks))\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'fastai.callbacks' has no attribute 'Scheduler'"
     ]
    }
   ],
   "source": [
    "## Model_name, ctc_accuracy, loss_function, optimizer\n",
    "models = [partial(model_file.model, DEVICE, WINDOW_SIZE, DIMENSIONS_PREDICTION_OUT)]\n",
    "with open('hyper-output', 'w') as f:\n",
    "    f.write('Model_name, ctc_accuracy, loss_function, optimizer')\n",
    "    for model in models:\n",
    "        for l_key, loss in loss_funcs.items():\n",
    "            for o_key, optim in optimizers.items():\n",
    "                m, MODEL_NAME = model()\n",
    "                MODEL_NAME = f'{MODEL_NAME}-windowsize={WINDOW_SIZE}'\n",
    "                MODEL_DIR = f'weights/{MODEL_NAME}'\n",
    "\n",
    "                # Create learner\n",
    "                learner = Learner(databunch, m, loss_func=loss, model_dir=MODEL_DIR, metrics=METRICS, opt_func=optim)\n",
    "                for s_key, attach_scheduler in named_schedulers.items():\n",
    "                    attach_scheduler(learner)\n",
    "                    \n",
    "                    # FIT\n",
    "                    learner.fit(EPOCHS, lr=LR)\n",
    "                    f.write(f'{MODEL_NAME}, {learner.validate()[1]}, {l_key}, {o_key}, {s_key}\\n')\n",
    "                    del m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
