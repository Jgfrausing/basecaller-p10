{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Databunch for Basecalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "\n",
    "import jkbc.utils.experimentation as e\n",
    "import jkbc.utils.files as f\n",
    "import jkbc.utils.loss as l\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import toml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK_ID       = pop.BLANK_ID\n",
    "ALPHABET       = pop.ALPHABET # {0: '-', 1: 'A', 2: 'B'}\n",
    "ALPHABET_VAL   = list(ALPHABET.values())\n",
    "ALPHABET_STR   = ''.join(ALPHABET_VAL)\n",
    "ALPHABET_SIZE  = len(ALPHABET_VAL)\n",
    "WINDOW_SIZE    = 300\n",
    "STRIDE         = 300\n",
    "DIMENSIONS_OUT = 70 #Max label len?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS_PREDICTION_OUT = 100     # DIMENSIONS_OUT*2-1\n",
    "DROP_LAST    = False # SET TO TRUE IF IT FAILS ON LAST BATCH\n",
    "## Add Model specific variables here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 1024  # batch size\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")\n",
    "MODEL_NAME = \"bonito_5000_10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = f'Range0-5000-FixLabelLen{DIMENSIONS_OUT}'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "data = f.read_data_from_feather_file(FEATHER_FOLDER)\n",
    "\n",
    "# Convert to databunch\n",
    "train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, drop_last=DROP_LAST)\n",
    "del data\n",
    "databunch = DataBunch(train_dl, valid_dl, device=DEVICE)\n",
    "del train_dl\n",
    "del valid_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = l.ctc_loss(DIMENSIONS_PREDICTION_OUT, BS, ALPHABET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: MAKE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "activations = {\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"leaky_relu\": nn.LeakyReLU,\n",
    "}\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Model template for QuartzNet style architectures\n",
    "\n",
    "    https://arxiv.org/pdf/1910.10261.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.stride = config['block'][0]['stride'][0]\n",
    "        self.alphabet = config['labels']['labels']\n",
    "        self.features = config['block'][-1]['filters']\n",
    "        self.encoder = Encoder(config)\n",
    "        self.decoder = Decoder(self.features, len(self.alphabet))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.decoder(encoded)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Builds the model encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        features = self.config['input']['features']\n",
    "        activation = activations[self.config['encoder']['activation']]()\n",
    "        encoder_layers = []\n",
    "\n",
    "        for layer in self.config['block']:\n",
    "            encoder_layers.append(\n",
    "                Block(\n",
    "                    features, layer['filters'], activation,\n",
    "                    repeat=layer['repeat'], kernel_size=layer['kernel'],\n",
    "                    stride=layer['stride'], dilation=layer['dilation'],\n",
    "                    dropout=layer['dropout'], residual=layer['residual'],\n",
    "                    separable=layer['separable'],\n",
    "                )\n",
    "            )\n",
    "\n",
    "            features = layer['filters']\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder([x])\n",
    "\n",
    "\n",
    "class TCSConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Time-Channel Separable 1D Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=False, separable=False):\n",
    "\n",
    "        super(TCSConv1d, self).__init__()\n",
    "        self.separable = separable\n",
    "\n",
    "        if separable:\n",
    "            self.depthwise = nn.Conv1d(\n",
    "                in_channels, in_channels, kernel_size=kernel_size, stride=stride,\n",
    "                padding=padding, dilation=dilation, bias=bias, groups=in_channels\n",
    "            )\n",
    "\n",
    "            self.pointwise = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=1, stride=stride,\n",
    "                dilation=dilation, bias=bias, padding=0\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Conv1d(\n",
    "                in_channels, out_channels, kernel_size=kernel_size,\n",
    "                stride=stride, padding=padding, dilation=dilation, bias=bias\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.separable:\n",
    "            x = self.depthwise(x)\n",
    "            x = self.pointwise(x)\n",
    "        else:\n",
    "            x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    TCSConv, Batch Normalisation, Activation, Dropout\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, activation, repeat=5, kernel_size=1, stride=1, dilation=1, dropout=0.0, residual=False, separable=False):\n",
    "\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.use_res = residual\n",
    "        self.conv = nn.ModuleList()\n",
    "\n",
    "        _in_channels = in_channels\n",
    "        padding = self.get_padding(kernel_size[0], stride[0], dilation[0])\n",
    "\n",
    "        # add the first n - 1 convolutions + activation\n",
    "        for _ in range(repeat - 1):\n",
    "            self.conv.extend(\n",
    "                self.get_tcs(\n",
    "                    _in_channels, out_channels, kernel_size=kernel_size,\n",
    "                    stride=stride, dilation=dilation,\n",
    "                    padding=padding, separable=separable\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.conv.extend(self.get_activation(activation, dropout))\n",
    "            _in_channels = out_channels\n",
    "\n",
    "        # add the last conv and batch norm\n",
    "        self.conv.extend(\n",
    "            self.get_tcs(\n",
    "                _in_channels, out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride, dilation=dilation,\n",
    "                padding=padding, separable=separable\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # add the residual connection\n",
    "        if self.use_res:\n",
    "            self.residual = nn.Sequential(*self.get_tcs(in_channels, out_channels))\n",
    "\n",
    "        # add the activation and dropout\n",
    "        self.activation = nn.Sequential(*self.get_activation(activation, dropout))\n",
    "\n",
    "    def get_activation(self, activation, dropout):\n",
    "        return activation, nn.Dropout(p=dropout)\n",
    "\n",
    "    def get_padding(self, kernel_size, stride, dilation):\n",
    "        if stride > 1 and dilation > 1:\n",
    "            raise ValueError(\"Dilation and stride can not both be greater than 1\")\n",
    "        return (kernel_size // 2) * dilation\n",
    "\n",
    "    def get_tcs(self, in_channels, out_channels, kernel_size=1, stride=1, dilation=1, padding=0, bias=False, separable=False):\n",
    "        return [\n",
    "            TCSConv1d(\n",
    "                in_channels, out_channels, kernel_size,\n",
    "                stride=stride, dilation=dilation, padding=padding,\n",
    "                bias=bias, separable=separable\n",
    "            ),\n",
    "            nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.1)\n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = x[0]\n",
    "        for layer in self.conv:\n",
    "            _x = layer(_x)\n",
    "        if self.use_res:\n",
    "            _x += self.residual(x[0])\n",
    "        return [self.activation(_x)]\n",
    "\n",
    "\n",
    "class Decoder(Module):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, features, classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.Sequential(nn.Conv1d(features, classes, kernel_size=1, bias=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x[-1])\n",
    "        return nn.functional.log_softmax(x.transpose(1, 2), dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = toml.load(\"quartznet5x5.toml\")\n",
    "model = Model(config).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(databunch, model, loss_func=loss_func, path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded for: bonito_5000_10\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learner = learner.load(MODEL_NAME)\n",
    "    print(f'Model weights loaded for: {MODEL_NAME}')\n",
    "except:\n",
    "    print('No model weights available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='8' class='' max='648', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      1.23% [8/648 00:09<12:56 1.5115]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-da3593d87630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuggestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(learn, start_lr, end_lr, num_it, stop_div, wd)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/fastai/callback.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpg2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jkbc/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(500, max_lr=learner.recorder.min_grad_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, (y, _) = databunch.one_batch()\n",
    "x_device = x.to(device=DEVICE)\n",
    "y_pred = model(x_device).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGACATCGAGGTGCCAAACCTCC\n",
      "CTGCAGGAT 5 0.7826086956521738\n",
      "CTGCAGAT 6 0.7391304347826086\n",
      "CTGCATGAT 7 0.6956521739130435\n",
      "CTGCATGATA 8 0.6521739130434783\n",
      "CATGCATGATA 9 0.782608695652174\n",
      "GTGCATGATA 10 0.8260869565217391\n",
      "CGTGCATGATA 11 0.782608695652174\n",
      "CGTGCATGATA 12 0.782608695652174\n",
      "CTGCATGATA 13 0.6521739130434783\n",
      "GTGCATGATA 14 0.8260869565217391\n",
      "CGTGCATGATA 15 0.782608695652174\n",
      "GTGCATGATA 16 0.8260869565217391\n",
      "CGTGCATGGTA 17 0.8695652173913043\n",
      "CGTGCATGGAT 18 0.782608695652174\n",
      "CGTGCATGGAT 19 0.782608695652174\n",
      "CGTGCATGGAT 20 0.782608695652174\n",
      "CTGCATGGAT 21 0.6956521739130435\n",
      "CTGCATGGAT 22 0.6956521739130435\n",
      "CGCACATGGAT 23 0.6521739130434782\n",
      "CGTGCATGGAT 24 0.782608695652174\n",
      "CGTGCATGGAT 25 0.782608695652174\n",
      "CGTGCATGGAT 26 0.782608695652174\n",
      "CGTGCATGGAT 27 0.782608695652174\n",
      "CGTGCATGGAT 28 0.782608695652174\n",
      "CGTGCATGGAT 29 0.782608695652174\n",
      "CGTGCATGGAT 30 0.782608695652174\n",
      "CGTGCATGGAT 31 0.782608695652174\n",
      "CGTGCATGGAT 32 0.782608695652174\n",
      "CGTGCATGGAT 33 0.782608695652174\n",
      "CGTGCATGGAT 34 0.782608695652174\n",
      "CGTGCATGGAT 35 0.782608695652174\n",
      "CGTGCATGGAT 36 0.782608695652174\n",
      "CGTGCATGGAT 37 0.782608695652174\n",
      "CGTGCATGGAT 38 0.782608695652174\n",
      "CGTACATGGAT 39 0.6521739130434782\n",
      "CGTACATGGAT 40 0.6521739130434782\n",
      "CGTACATGGAT 41 0.6521739130434782\n",
      "CGTACATGGAT 42 0.6521739130434782\n",
      "CGTACATGGAT 43 0.6521739130434782\n",
      "CGTACATGGAT 44 0.6521739130434782\n",
      "CGTACATGGAT 45 0.6521739130434782\n",
      "CGTACATGGAT 46 0.6521739130434782\n",
      "CGTACATGGAT 47 0.6521739130434782\n",
      "CGTACATGGAT 48 0.6521739130434782\n",
      "CGTACATGGAT 49 0.6521739130434782\n",
      "\n",
      "AGATGATTCGTCTAATGTCGTCCTTTG\n",
      "CTCCTGCTCTA 5 0.7407407407407407\n",
      "CTGCTCGCTCAT 6 0.7037037037037037\n",
      "CTGCTCGCTCAT 7 0.7037037037037037\n",
      "CCTCTCGCGCTA 8 0.7407407407407407\n",
      "GCTCTCGCTCTA 9 0.7037037037037037\n",
      "CTCTCGCGCTA 10 0.7407407407407407\n",
      "CTCTCGCGCTA 11 0.7407407407407407\n",
      "CTGCTCGCTCTA 12 0.7037037037037037\n",
      "GCTCTCGCTCTA 13 0.7037037037037037\n",
      "CCTCTCGCTCTA 14 0.7407407407407407\n",
      "CCTCTCGCTCTA 15 0.7407407407407407\n",
      "CATCTCCTGCTA 16 0.7777777777777778\n",
      "CTGCTCGCGCTA 17 0.7037037037037037\n",
      "CCTCTACGTGCTA 18 0.6296296296296295\n",
      "CCTCTACGTGCTA 19 0.6296296296296295\n",
      "CCTCTACGCGCTA 20 0.6666666666666666\n",
      "CCTCTACGCGCTA 21 0.6666666666666666\n",
      "CCTCTACGCGCTA 22 0.6666666666666666\n",
      "CTCTACCGCGCTA 23 0.6666666666666666\n",
      "CTCTACCGCGCTA 24 0.6666666666666666\n",
      "CCTCTACGCGCTA 25 0.6666666666666666\n",
      "CCTCTACGCTGCTA 26 0.6666666666666666\n",
      "CTCTACCGTGCTA 27 0.6296296296296295\n",
      "CCTGCTCCGTCGTA 28 0.6296296296296295\n",
      "CTCTACCGTCGTA 29 0.6296296296296295\n",
      "CTCTACCGTCGTA 30 0.6296296296296295\n",
      "CTCTACCGTCGTA 31 0.6296296296296295\n",
      "CTCTACCGTCGTA 32 0.6296296296296295\n",
      "CTCTACCGTCGTA 33 0.6296296296296295\n",
      "CTCTACCGTCGTA 34 0.6296296296296295\n",
      "GCTCTACGCTCTA 35 0.6666666666666666\n",
      "CTCTACGCTGCTA 36 0.6666666666666666\n",
      "CTCTACGCTGCTA 37 0.6666666666666666\n",
      "CTCTACGCTGCTA 38 0.6666666666666666\n",
      "CTCTACGCTGCTA 39 0.6666666666666666\n",
      "CTCTACGCTGCTA 40 0.6666666666666666\n",
      "CTCTACGCTGCTA 41 0.6666666666666666\n",
      "CTCTACGCTGCTA 42 0.6666666666666666\n",
      "CCTCTACGCTGCTA 43 0.6666666666666666\n",
      "CTCTACGCTGCTA 44 0.6666666666666666\n",
      "CCTCTACGCTGCTA 45 0.6666666666666666\n",
      "CTCTACGCTGCTA 46 0.6666666666666666\n",
      "CCTCTACGCTGCTA 47 0.6666666666666666\n",
      "CTCTACGCTGCTA 48 0.6666666666666666\n",
      "CTCTACGCTGCTA 49 0.6666666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = range(min(5, DIMENSIONS_PREDICTION_OUT), min(DIMENSIONS_PREDICTION_OUT+1, 50)) #Range can't contain values larger than PRED_OUT_DIM\n",
    "\n",
    "for index in [0, BS-1]:\n",
    "    actual = pop.convert_idx_to_base_sequence(y[index], ALPHABET_VAL)\n",
    "    prediction = y_pred[index]\n",
    "    for pred, beam, error in e.get_stats(prediction, actual, ALPHABET_STR, r):\n",
    "        print(pred, beam, error.error)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run assemble only if data is not fetched from featherfile\n",
    "# TODO: Assembled should not be on a batch, but instead on a complete signal\n",
    "if STRIDE != WINDOW_SIZE:\n",
    "    decoded = pop.decode(y_pred, ALPHABET_STR, beam_size=15)\n",
    "    assembled = pop.assemble(decoded, WINDOW_SIZE, STRIDE, ALPHABET)\n",
    "    print('Assembled:', assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
