{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jkbc.model as m\n",
    "import jkbc.model.factory as factory\n",
    "import jkbc.constants as constants\n",
    "import jkbc.files.torch_files as f\n",
    "import jkbc.model.metrics as metric\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.files.fasta as fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = 'Range0-50-FixLabelLen400-winsize4096'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET\n",
    "\n",
    "with open(FEATHER_FOLDER/'config.json', 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "ALPHABET       = constants.ALPHABET\n",
    "ALPHABET_VAL   = list(ALPHABET.values())\n",
    "ALPHABET_STR   = ''.join(ALPHABET_VAL)\n",
    "ALPHABET_SIZE  = len(ALPHABET.keys())\n",
    "WINDOW_SIZE    = int(config['maxw']) #maxw = max windowsize\n",
    "DIMENSIONS_OUT = int(config['maxl']) # maxl = max label length\n",
    "\n",
    "KNOWLEGDE_DISTILLATION = True\n",
    "TEACHER_OUTPUT = 'bonito-csv' # Set to name of y_teacher output\n",
    "if KNOWLEGDE_DISTILLATION and not TEACHER_OUTPUT:\n",
    "    print('WARNING! Must provide name of teacher output when doing knowledge distillation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3  # default learning rate\n",
    "BS = 2**6  # batch size\n",
    "EPOCHS = 400\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_LAST = False # SET TO TRUE IF IT FAILS ON LAST BATCH\n",
    "model, (MODEL_NAME, pred_dim_out) = factory.bonito(WINDOW_SIZE, DEVICE, BASE_DIR)\n",
    "MODEL_NAME = f'{MODEL_NAME}-student'\n",
    "MODEL_DIR = f'{MODEL_NAME}/weights'\n",
    "model_weights = None#'bestmodel_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to get newest model\n",
    "if not model_weights:\n",
    "    model_weights = m.get_newest_model(MODEL_DIR)\n",
    "print(model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, metrics and callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ctc_loss = metric.CtcLoss(WINDOW_SIZE, pred_dim_out, BS, ALPHABET_SIZE)\n",
    "_kd_loss = metric.KdLoss(alpha=.05, temperature=20, label_loss=_ctc_loss)\n",
    "LOSS_FUNC = _kd_loss.loss() if KNOWLEGDE_DISTILLATION else _ctc_loss.loss()\n",
    "\n",
    "METRICS = [metric.ctc_accuracy(ALPHABET, 5)]\n",
    "SAVE_CALLBACK = partial(metric.SaveModelCallback, every='epoch', monitor='ctc_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "if KNOWLEGDE_DISTILLATION:\n",
    "    data, teacher = f.load_training_data_with_teacher(FEATHER_FOLDER, TEACHER_OUTPUT)\n",
    "    train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, teacher=teacher, drop_last=DROP_LAST)\n",
    "else:\n",
    "    data = f.load_training_data(FEATHER_FOLDER) \n",
    "    train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, drop_last=DROP_LAST)\n",
    "\n",
    "# Convert to databunch\n",
    "databunch = DataBunch(train_dl, valid_dl, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = partial(torch.optim.AdamW, amsgrad=True, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(databunch, model, loss_func=LOSS_FUNC, model_dir=MODEL_DIR, metrics=METRICS, opt_func=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    learner.load(model_weights)\n",
    "    print(f'{model_weights} loaded')\n",
    "except:\n",
    "    print(f'No model could be found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default to LR if lr_find() has not been run\n",
    "try: lr = learner.recorder.min_grad_lr\n",
    "except: lr = LR\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(EPOCHS, lr=lr, callbacks=[SAVE_CALLBACK(learner), metric.CSVLogger(learner, filename=f'{MODEL_NAME}/history.csv', append=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
