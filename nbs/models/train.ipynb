{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jkbc.model as m\n",
    "import jkbc.model.factory as factory\n",
    "import jkbc.utils.constants as constants\n",
    "import jkbc.utils.torch_files as f\n",
    "import jkbc.utils.metrics as metric\n",
    "import jkbc.utils.preprocessing as prep\n",
    "import jkbc.utils.postprocessing as pop\n",
    "import jkbc.utils.fasta as fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"../..\")\n",
    "PATH_DATA = 'data/feather-files'\n",
    "DATA_SET = 'Range0-50-FixLabelLen400-winsize4096'\n",
    "FEATHER_FOLDER = BASE_DIR/PATH_DATA/DATA_SET\n",
    "\n",
    "with open(FEATHER_FOLDER/'config.json', 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "\n",
    "ALPHABET       = constants.ALPHABET\n",
    "ALPHABET_VAL   = list(ALPHABET.values())\n",
    "ALPHABET_STR   = ''.join(ALPHABET_VAL)\n",
    "ALPHABET_SIZE  = len(ALPHABET.keys())\n",
    "WINDOW_SIZE    = int(config['maxw']) #maxw = max windowsize\n",
    "DIMENSIONS_OUT = int(config['maxl']) # maxl = max label length\n",
    "STRIDE         = WINDOW_SIZE\n",
    "\n",
    "KNOWLEGDE_DISTILLATION = True\n",
    "TEACHER_OUTPUT = 'bonito-csv' # Set to name of y_teacher output\n",
    "if KNOWLEGDE_DISTILLATION and not TEACHER_OUTPUT:\n",
    "    print('WARNING! Must provide name of teacher output when doing knowledge distillation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3  # default learning rate\n",
    "BS = 2**6  # batch size\n",
    "EPOCHS = 400\n",
    "DEVICE = torch.device(\"cuda:0\") #torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS_PREDICTION_OUT = WINDOW_SIZE//3+1\n",
    "DROP_LAST = False # SET TO TRUE IF IT FAILS ON LAST BATCH\n",
    "model, MODEL_NAME = factory.bonito(DEVICE, BASE_DIR)\n",
    "MODEL_NAME = f'{MODEL_NAME}-student'\n",
    "MODEL_DIR = f'{MODEL_NAME}/weights'\n",
    "model_weights = None#'bestmodel_8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp\n"
     ]
    }
   ],
   "source": [
    "# Run to get newest model\n",
    "if not model_weights:\n",
    "    model_weights = m.get_newest_model(MODEL_DIR)\n",
    "print(model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, metrics and callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ctc_loss = metric.CtcLoss(WINDOW_SIZE, DIMENSIONS_PREDICTION_OUT, BS, ALPHABET_SIZE)\n",
    "_kd_loss = metric.KdLoss(alpha=.05, temperature=20, label_loss=_ctc_loss)\n",
    "LOSS_FUNC = _kd_loss.loss() if KNOWLEGDE_DISTILLATION else _ctc_loss.loss()\n",
    "\n",
    "METRICS = [metric.ctc_accuracy(ALPHABET, 5)]\n",
    "SAVE_CALLBACK = partial(metric.SaveModelCallback, every='epoch', monitor='ctc_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from feather\n",
    "if KNOWLEGDE_DISTILLATION:\n",
    "    data, teacher = f.load_training_data_with_teacher(FEATHER_FOLDER, TEACHER_OUTPUT)\n",
    "    train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, teacher=teacher, drop_last=DROP_LAST)\n",
    "else:\n",
    "    data = f.load_training_data(FEATHER_FOLDER) \n",
    "    train_dl, valid_dl = prep.convert_to_dataloaders(data, split=.8, batch_size=BS, drop_last=DROP_LAST)\n",
    "\n",
    "# Convert to databunch\n",
    "databunch = DataBunch(train_dl, valid_dl, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = partial(torch.optim.AdamW, amsgrad=True, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(databunch, model, loss_func=LOSS_FUNC, model_dir=MODEL_DIR, metrics=METRICS, opt_func=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learner.load(model_weights)\n",
    "    print(f'{model_weights} loaded')\n",
    "except:\n",
    "    print(f'No model could be found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>ctc_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='42', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/42 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default to LR if lr_find() has not been run\n",
    "try: lr = learner.recorder.min_grad_lr\n",
    "except: lr = LR\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(EPOCHS, lr=lr, callbacks=[SAVE_CALLBACK(learner), metric.CSVLogger(learner, filename=f'{MODEL_NAME}/history.csv', append=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "jkbc",
   "language": "python",
   "name": "jkbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
